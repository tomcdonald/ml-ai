{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of Lab 3 - Linear Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7AOIlNGUEQEA",
        "2QKWP2-yEQEB",
        "cfojd2l7EQEC",
        "_wB5QekjEQEq",
        "QcPol7DZEQEr",
        "om_qbpOiEQEs"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomcdonald/ml-ai/blob/master/labs/Lab%203%20-%20Linear%20Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBTrVol0EQDj",
        "colab_type": "text"
      },
      "source": [
        "# Linear Algebra and Linear Regression\n",
        "\n",
        "### Modified by Mauricio √Ålvarez, 13th October 2019\n",
        "\n",
        "### 13th October 2015 Neil Lawrence\n",
        "\n",
        "\n",
        "## Sum of Squares Error\n",
        "\n",
        "Last week we considered a cost function for minimization of the error. We considered items (films) and users and assumed that each movie rating, $y_{i,j}$ could be summarised by an inner product between a vector associated with the item, $\\mathbf{v}_j$ and one associated with the user $\n",
        "\\mathbf{u}_i$. We justified the inner product as a measure of similarity in the space of 'movie subjects', where both the users and the items lived, giving the analogy of a library.\n",
        "\n",
        "To make predictions we encouraged the similarity to be high if the movie rating was high using the quadratic error function,\n",
        "$$\n",
        "E_{i,j}(\\mathbf{u}_i, \\mathbf{v}_j) = \\left(\\mathbf{u}_i^\\top \\mathbf{v}_j - y_{i,j}\\right)^2,\n",
        "$$\n",
        "which we then summed across all the observations to form the total error\n",
        "$$\n",
        "E(\\mathbf{U}, \\mathbf{V}) = \\sum_{i,j}s_{i,j}\\left(\\mathbf{u}_i^\\top \\mathbf{v}_j - y_{i,j}\\right)^2,\n",
        "$$\n",
        "where $s_{i,j}$ is an indicator variable which is set to 1 if the rating of movie $j$ by user $i$ is provided in our data set. \n",
        "\n",
        "This is known as a sum of squares error. Minimizing it was first proposed by [Legendre](http://en.wikipedia.org/wiki/Adrien-Marie_Legendre) in 1805. His book, which was on the orbit of comets, is available on google books, we can take a look at the relevant page by calling the code below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctnstZcvEpo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df3f6d31-ba28-4cdf-9123-adaaad9c90b1"
      },
      "source": [
        "! pip install pods"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pods in /usr/local/lib/python3.6/dist-packages (0.0.2a0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtomBt7OEQDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "2dd3bc78-2696-449d-ba5e-dc03e25dd32a"
      },
      "source": [
        "import pods\n",
        "pods.notebook.display_google_book(id='spcAAAAAMAAJ', page=72) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe frameborder=\"0\" scrolling=\"yes\" style=\"border:0px\" src=\"http://books.google.co.uk/books?id=spcAAAAAMAAJ&pg=PA72&output=embed\", width=700 height=500></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPtUf6ykEQDq",
        "colab_type": "text"
      },
      "source": [
        "Of course, the main text is in French, but the key part we are interested in can be roughly translated as\n",
        "\n",
        "\"In most matters where we take measures data through observation, the most accurate results they can offer, it is almost always leads to a system of equations of the form\n",
        "$$E = a + bx + cy + fz + etc .$$\n",
        "where a, b, c, f etc are the known coefficients and  x , y, z etc are unknown and must be determined by the condition that the value of E is reduced, for each equation, to an amount or zero or very small.\"\n",
        "\n",
        "He continues\n",
        "\n",
        "\"Of all the principles that we can offer for this item, I think it is not broader, more accurate, nor easier than the one we have used in previous research application, and that is to make the minimum sum of the squares of the errors. By this means, it is between the errors a kind of balance that prevents extreme to prevail, is very specific to make known the state of the closest to the truth system. The sum of the squares of the errors $E^2 + \\left.E^\\prime\\right.^2 + \\left.E^{\\prime\\prime}\\right.^2 + etc$ being\n",
        "\\begin{align*}   &(a + bx + cy + fz + etc)^2 \\\\\n",
        "+ &(a^\\prime + b^\\prime x + c^\\prime y + f^\\prime z + etc ) ^2\\\\\n",
        "+ &(a^{\\prime\\prime} + b^{\\prime\\prime}x  + c^{\\prime\\prime}y +  f^{\\prime\\prime}z + etc )^2 \\\\\n",
        "+ & etc\n",
        "\\end{align*}\n",
        "if we wanted a minimum, by varying x alone, we will have the equation ...\"\n",
        "\n",
        "This is the earliest know printed version of the problem of least squares. The notation, however, is a little awkward for mordern eyes. In particular Legendre doesn't make use of the sum sign,\n",
        "$$\n",
        "\\sum_{i=1}^3 z_i = z_1 + z_2 + z_3\n",
        "$$\n",
        "nor does he make use of the inner product. \n",
        "\n",
        "In our notation, if we were to do linear regression, we would need to subsititue:\n",
        "\\begin{align*}\n",
        "a &\\leftarrow y_1-c, \\\\ a^\\prime &\\leftarrow y_2-c,\\\\ a^{\\prime\\prime} &\\leftarrow y_3 -c,\\\\ \n",
        "\\text{etc.} \n",
        "\\end{align*}\n",
        "to introduce the data observations $\\{y_i\\}_{i=1}^{n}$ alongside $c$, the offset. We would then introduce the input locations\n",
        "\\begin{align*}\n",
        "b & \\leftarrow x_1,\\\\\n",
        "b^\\prime & \\leftarrow x_2,\\\\\n",
        "b^{\\prime\\prime} & \\leftarrow x_3\\\\\n",
        "\\text{etc.}\n",
        "\\end{align*}\n",
        "and finally the gradient of the function\n",
        "$$x \\leftarrow -m.$$\n",
        "The remaining coefficients ($c$ and $f$) would then be zero. That would give us \n",
        "\\begin{align*}   &(y_1 - (mx_1+c))^2 \\\\\n",
        "+ &(y_2 -(mx_2 + c))^2\\\\\n",
        "+ &(y_3 -(mx_3 + c))^2 \\\\\n",
        "+ & \\text{etc.}\n",
        "\\end{align*}\n",
        "which we would write in the modern notation for sums as\n",
        "$$\n",
        "\\sum_{i=1}^n (y_i-(mx_i + c))^2\n",
        "$$\n",
        "which is recognised as the sum of squares error for a linear regression.\n",
        "\n",
        "This shows the advantage of modern [summation operator](http://en.wikipedia.org/wiki/Summation), $\\sum$,  in keeping our mathematical notation compact. Whilst it may look more complicated the first time you see it, understanding the mathematical rules that go around it, allows us to go much further with the notation.\n",
        "\n",
        "Inner products (or [dot products](http://en.wikipedia.org/wiki/Dot_product)) are similar. They allow us to write\n",
        "$$\n",
        "\\sum_{i=1}^q u_i v_i\n",
        "$$\n",
        "in a more compact notation,\n",
        "$\n",
        "\\mathbf{u}\\cdot\\mathbf{v}.\n",
        "$\n",
        "\n",
        "Here we are using bold face to represent vectors, and we assume that the individual elements of a vector $\\mathbf{z}$ are given as a series of scalars\n",
        "$$\n",
        "\\mathbf{z} = \\begin{bmatrix} z_1\\\\ z_2\\\\ \\vdots\\\\ z_n \\end{bmatrix}\n",
        "$$\n",
        "which are each indexed by their position in the vector.\n",
        "\n",
        "## Linear Algebra\n",
        "\n",
        "Linear algebra provides a very similar role, when we introduce [linear algebra](http://en.wikipedia.org/wiki/Linear_algebra), it is because we are faced with a large number of addition and multiplication operations. These operations need to be done together and would be very tedious to write down as a group. So the first reason we reach for linear algebra is for a more compact representation of our mathematical formulae. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nek05icyEQDr",
        "colab_type": "text"
      },
      "source": [
        "### Running Example: Olympic Marathons\n",
        "\n",
        "Now we will load in the Olympic marathon data. This is data of the olympic marath times for the men's marathon from the first olympics in 1896 up until the London 2012 olympics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adZMMJQHEQDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pods.datasets.olympic_marathon_men()\n",
        "x = data['X']\n",
        "y = data['Y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJn6XqWlEQDx",
        "colab_type": "text"
      },
      "source": [
        "You can see what these values are by typing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfXxsnrAEQDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "a1f0f075-5604-4c0c-9000-69a90b5d38e0"
      },
      "source": [
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1896.]\n",
            " [1900.]\n",
            " [1904.]\n",
            " [1908.]\n",
            " [1912.]\n",
            " [1920.]\n",
            " [1924.]\n",
            " [1928.]\n",
            " [1932.]\n",
            " [1936.]\n",
            " [1948.]\n",
            " [1952.]\n",
            " [1956.]\n",
            " [1960.]\n",
            " [1964.]\n",
            " [1968.]\n",
            " [1972.]\n",
            " [1976.]\n",
            " [1980.]\n",
            " [1984.]\n",
            " [1988.]\n",
            " [1992.]\n",
            " [1996.]\n",
            " [2000.]\n",
            " [2004.]\n",
            " [2008.]\n",
            " [2012.]]\n",
            "[[4.47083333]\n",
            " [4.46472926]\n",
            " [5.22208333]\n",
            " [4.15467867]\n",
            " [3.90331675]\n",
            " [3.56951267]\n",
            " [3.82454477]\n",
            " [3.62483707]\n",
            " [3.59284275]\n",
            " [3.53880792]\n",
            " [3.67010309]\n",
            " [3.39029111]\n",
            " [3.43642612]\n",
            " [3.20583007]\n",
            " [3.13275665]\n",
            " [3.32819844]\n",
            " [3.13583758]\n",
            " [3.0789588 ]\n",
            " [3.10581822]\n",
            " [3.06552909]\n",
            " [3.09357349]\n",
            " [3.16111704]\n",
            " [3.14255244]\n",
            " [3.08527867]\n",
            " [3.10265829]\n",
            " [2.99877553]\n",
            " [3.03392977]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToQ7QQRNEQD0",
        "colab_type": "text"
      },
      "source": [
        "Note that they are not `pandas` data frames for this example, they are just arrays of dimensionality $n\\times 1$, where $n$ is the number of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dt3v98SEQD0",
        "colab_type": "text"
      },
      "source": [
        "The aim of this lab is to have you coding linear regression in python. We will do it in two ways, once using iterative updates (coordinate ascent) and then using linear algebra. The linear algebra approach will not only work much better, it is easy to extend to multiple input linear regression and *non-linear* regression using basis functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5CM9JcTEQD1",
        "colab_type": "text"
      },
      "source": [
        "### Plotting the Data\n",
        "\n",
        "You can make a plot of $y$ vs $x$ with the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqwajs-mEQD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "60f57f0f-915c-43c6-a2b9-27af8da957a1"
      },
      "source": [
        "%matplotlib inline \n",
        "import pylab as plt\n",
        "\n",
        "plt.plot(x, y, 'rx')\n",
        "plt.xlabel('year')\n",
        "plt.ylabel('pace in min/km')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'pace in min/km')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSxIrr9OEQD4",
        "colab_type": "text"
      },
      "source": [
        "### Maximum Likelihood: Iterative Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXl4pH6nEQD5",
        "colab_type": "text"
      },
      "source": [
        "Now we will take the maximum likelihood approach we derived in the lecture to fit a line, $y_i=mx_i + c$, to the data you've plotted. We are trying to minimize the error function:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGyMYn_KEQD5",
        "colab_type": "text"
      },
      "source": [
        "$$E(m, c) =  \\sum_{i=1}^n(y_i-mx_i-c)^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkUN-YxkEQD6",
        "colab_type": "text"
      },
      "source": [
        "with respect to $m$, $c$ and $\\sigma^2$. We can start with an initial guess for $m$, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1mBYxnyEQD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = -0.4\n",
        "c = 80 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kerW9u1ZEQD9",
        "colab_type": "text"
      },
      "source": [
        "Then we use the maximum likelihood update to find an estimate for the offset, $c$.\n",
        "\n",
        "### Coordinate Descent\n",
        "\n",
        "In the movie recommender system example, we minimised the objective function by steepest descent based gradient methods. Our updates required us to compute the gradient at the position we were located, then to update the gradient according to the direction of steepest descent. This time, we will take another approach. It is known as *coordinate descent*. In coordinate descent, we choose to move one parameter at a time. Ideally, we design an algorithm that at each step moves the parameter to its minimum value. At each step we choose to move the individual parameter to its minimum.\n",
        "\n",
        "To find the minimum, we look for the point in the curve where the gradient is zero. This can be found by taking the gradient of $E(m,c)$ with respect to the parameter. \n",
        "\n",
        "#### Update for Offset\n",
        "\n",
        "Let's consider the parameter $c$ first. The gradient goes nicely through the summation operator, and we obtain\n",
        "$$\n",
        "\\frac{\\text{d}E(m,c)}{\\text{d}c} = -\\sum_{i=1}^n 2(y_i-mx_i-c).\n",
        "$$\n",
        "Now we want the point that is a minimum. A minimum is an example of a [*stationary point*](http://en.wikipedia.org/wiki/Stationary_point), the stationary points are those points of the function where the gradient is zero. They are found by solving the equation for $\\frac{\\text{d}E(m,c)}{\\text{d}c} = 0$. Substituting in to our gradient, we can obtain the following equation, \n",
        "$$\n",
        "0 = -\\sum_{i=1}^n 2(y_i-mx_i-c)\n",
        "$$\n",
        "which can be reorganised as follows,\n",
        "$$\n",
        "c^* = \\frac{\\sum_{i=1}^n(y_i-m^*x_i)}{n}.\n",
        "$$\n",
        "The fact that the stationary point is easily extracted in this manner implies that the solution is *unique*. There is only one stationary point for this system. Traditionally when trying to determine the type of stationary point we have encountered we now compute the *second derivative*,\n",
        "$$\n",
        "\\frac{\\text{d}^2E(m,c)}{\\text{d}c^2} = 2n.\n",
        "$$\n",
        "The second derivative is positive, which in turn implies that we have found a minimum of the function. This means that setting $c$ in this way will take us to the lowest point along that axes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS0v67CEEQD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6618052e-c628-417c-b957-cbe05960e5b7"
      },
      "source": [
        "# set c to the minimum\n",
        "c = (y - m*x).mean()\n",
        "print(c)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "786.0197711453593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AOIlNGUEQEA",
        "colab_type": "text"
      },
      "source": [
        "#### Update for Slope\n",
        "\n",
        "Now we have the offset set to the minimum value, in coordinate descent, the next step is to optimise another parameter. Only one further parameter remains. That is the slope of the system. \n",
        "\n",
        "Now we can turn our attention to the slope. We once again peform the same set of computations to find the minima. We end up with an update equation of the following form.\n",
        "\n",
        "$$m^* = \\frac{\\sum_{i=1}^n (y_i - c)x_i}{\\sum_{i=1}^n x_i^2}$$\n",
        "\n",
        "Communication of mathematics in data science is an essential skill, in a moment, you will be asked to rederive the equation above. Before we do that, however, we will briefly review how to write mathematics in the notebook.\n",
        "\n",
        "### $\\LaTeX$ for Maths\n",
        "\n",
        "These cells use [Markdown format](http://en.wikipedia.org/wiki/Markdown). You can include maths in your markdown using [$\\LaTeX$ syntax](http://en.wikipedia.org/wiki/LaTeX), all you have to do is write your answer inside dollar signs, as follows:\n",
        "\n",
        "To write a fraction, we write `$\\frac{a}{b}$`, and it will display like this $\\frac{a}{b}$. To write a subscript we write `$a_b$` which will appear as $a_b$. To write a superscript (for example in a polynomial) we write `$a^b$` which will appear as $a^b$. There are lots of other macros as well, for example we can do greek letters such as `$\\alpha, \\beta, \\gamma$` rendering as $\\alpha, \\beta, \\gamma$. And we can do sum and intergral signs as `$\\sum \\int \\int$`.\n",
        "\n",
        "You can combine many of these operations together for composing expressions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LiDN01TEQEB",
        "colab_type": "text"
      },
      "source": [
        "### Question 1 \n",
        "\n",
        "Convert the following python code expressions into $\\LaTeX$j, writing your answers below. In each case write your answer as a single equality (i.e. your maths should only contain one expression, not several lines of expressions). For the purposes of your $\\LaTeX$ please assume that `x` and `w` are $n$ dimensional vectors. \n",
        "\n",
        "(a) \n",
        "``` python\n",
        "f = x.sum()\n",
        "```\n",
        "\n",
        "(b) \n",
        "``` python \n",
        "m = x.mean()\n",
        "```\n",
        "\n",
        "(c) \n",
        "``` python\n",
        "g = (x*w).sum()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QKWP2-yEQEB",
        "colab_type": "text"
      },
      "source": [
        "#### Question 1 Answer\n",
        "\n",
        "(a) \\begin{equation}f = \\sum_{i=1}^n x_i \\end{equation}\n",
        "\n",
        "(b) \\begin{equation}m = \\frac{\\sum_{i=1}^n x_i}{n} \\end{equation}\n",
        "\n",
        "(c) \\begin{equation}g = \\sum_{i=1}^n x_i w_i  \\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfojd2l7EQEC",
        "colab_type": "text"
      },
      "source": [
        "### Gradient With Respect to the Slope\n",
        "Now that you've had a little training in writing maths with $\\LaTeX$, we will be able to use it to answer questions. The next thing we are going to do is a little differentiation practice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL0-duMzEQED",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Derive the the gradient of the objective function with respect to the slope, $m$. Rearrange it to show that the update equation written above does find the stationary points of the objective function. By computing its derivative show that it's a minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAFy6xTMEQED",
        "colab_type": "text"
      },
      "source": [
        "#### Question 2 Answer\n",
        "\n",
        "Objective Function is given by:  $E(m, c) =  \\sum_{i=1}^n(y_i-mx_i-c)^2$\n",
        "\n",
        "We take the derivative with respect to $m$, arriving at:\n",
        "\n",
        "\\begin{aligned} \n",
        "\\frac{dE(m,c)}{dm} &= \\sum_{i=1}^n -2x_i(y_i-mx_i-c) \\\\ \n",
        "&= \\sum_{i=1}^n 2mx_i^2 - 2x_iy_i + 2x_ic \\\\\n",
        "&= 2\\sum_{i=1}^n mx_i^2 + x_i(c-y_i)\n",
        "\\end{aligned}\n",
        "\n",
        "We can now set this to zero, to find the stationary points of the function wrt. $m$ (we can ignore the factor of 2 as it cancels when we set to zero):\n",
        "\n",
        "\\begin{aligned} \n",
        "\\sum_{i=1}^n mx_i^2 + x_i(c-y_i) &= 0 \\\\ \n",
        "m^* = \\frac{\\sum_{i=1}^n x_i(y_i-c)}{\\sum_{i=1}^n x_i^2}  \\\\\n",
        "\\end{aligned}\n",
        "\n",
        "We can also confirm that this point is a minimum by computing the second derivative wrt. $m$:\n",
        "\n",
        "\\begin{aligned}\n",
        "\\frac{d^2E(m, c)}{dm^2} &= 2\\sum_{i=1}^n mx_i^2 + x_i(c-y_i) \\\\\n",
        "&= 4\\sum_{i=1}^n x_i\n",
        "\\end{aligned}\n",
        "\n",
        "And since all values of $x_i$ are positive, we can confirm that the second derivative is positive and therefore the point we have found is a minimum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fINmWJw5EQEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47bb298c-7046-40f5-d94e-878d600b7b6c"
      },
      "source": [
        "m = ((y - c)*x).sum()/(x**2).sum()\n",
        "print(m)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.3998724072997095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saibFzn3EQEG",
        "colab_type": "text"
      },
      "source": [
        "We can have a look at how good our fit is by computing the prediction across the input space. First create a vector of 'test points',"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWKAMMdZEQEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x_test = np.linspace(1890, 2020, 130)[:, None]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGBqKycKEQEK",
        "colab_type": "text"
      },
      "source": [
        "Now use this vector to compute some test predictions,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpBpf6lxEQEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_test = m*x_test + c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAXdS3feEQEP",
        "colab_type": "text"
      },
      "source": [
        "Now plot those test predictions with a blue line on the same plot as the data,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFb9iv9qEQEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f86dd0bc-889c-4dbf-92df-561de7b3ea14"
      },
      "source": [
        "plt.plot(x_test, f_test, 'b-')\n",
        "plt.plot(x, y, 'rx')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f005e22ac18>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngS8ikhAKfBGRhFDgi4gkxP8Bafl4UYRLum4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQQvPAFcEQES",
        "colab_type": "text"
      },
      "source": [
        "The fit isn't very good, we need to iterate between these parameter updates in a loop to improve the fit, we have to do this several times,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez3LlDjuEQET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36ee6514-5452-45d0-a2bd-6bef6cca2c25"
      },
      "source": [
        "for i in np.arange(10):\n",
        "    m = ((y - c)*x).sum()/(x*x).sum()\n",
        "    c = (y-m*x).sum()/y.shape[0]\n",
        "print(m)\n",
        "print(c)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.3987259642505432\n",
            "783.5273797273478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U5HWvMsEQEV",
        "colab_type": "text"
      },
      "source": [
        "And let's try plotting the result again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enw4uzSxEQEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "4da2588a-c3c2-4c9a-c752-6f87983ec0a4"
      },
      "source": [
        "f_test = m*x_test + c\n",
        "plt.plot(x_test, f_test, 'b-')\n",
        "plt.plot(x, y, 'rx')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f005b8c8b00>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttQ_1y5gEQEY",
        "colab_type": "text"
      },
      "source": [
        "Clearly we need more iterations than 10! In the next question you will add more iterations and report on the error as optimisation proceeds. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KnZizlHEQEY",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "There is a problem here, we seem to need many interations to get to a good solution. Let's explore what's going on. Write code which alternates between updates of `c` and `m`. Include the following features in your code.\n",
        "\n",
        "(a) Initialise with `m=-0.4` and `c=80`.\n",
        "(b) Every 10 iterations compute the value of the objective function for the training data and print it to the screen (you'll find hints on this in the lab from last week.\n",
        "(c) Cause the code to stop running when the error change over less than 10 iterations is smaller than $1\\times10^{-4}$. This is known as a stopping criterion.\n",
        "\n",
        "Why do we need so many iterations to get to the solution?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVZ-8x86EQEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4542464-b37a-4d58-b7dc-7bc30bb037e2"
      },
      "source": [
        "# Question 3 Answer Code\n",
        "# Write code for you answer to this question in this box\n",
        "m = -0.4\n",
        "c = 80\n",
        "last_error = 999999\n",
        "error_change_10 = 999999\n",
        "\n",
        "for i in range(100000):\n",
        "    if i % 10 == 0 and i!=0:\n",
        "        current_error = np.square(y-m*x-c).sum()\n",
        "        print('Iteration', i, ', obj. function =', current_error)\n",
        "        error_change_10 = current_error - last_error\n",
        "        if error_change_10 > -10**-4:\n",
        "            break\n",
        "        last_error = current_error\n",
        "    m = ((y - c)*x).sum()/(x*x).sum()\n",
        "    c = (y-m*x).sum()/y.shape[0]\n",
        "\n",
        "f_test = m*x_test + c\n",
        "plt.plot(x_test, f_test, 'b-')\n",
        "plt.plot(x, y, 'rx')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 10 , obj. function = 25.082467969685627\n",
            "Iteration 20 , obj. function = 24.930615384247915\n",
            "Iteration 30 , obj. function = 24.779760925570276\n",
            "Iteration 40 , obj. function = 24.629898032967365\n",
            "Iteration 50 , obj. function = 24.481020188877213\n",
            "Iteration 60 , obj. function = 24.33312091857767\n",
            "Iteration 70 , obj. function = 24.1861937899053\n",
            "Iteration 80 , obj. function = 24.040232412974916\n",
            "Iteration 90 , obj. function = 23.895230439901937\n",
            "Iteration 100 , obj. function = 23.751181564526696\n",
            "Iteration 110 , obj. function = 23.608079522139967\n",
            "Iteration 120 , obj. function = 23.465918089210145\n",
            "Iteration 130 , obj. function = 23.324691083113112\n",
            "Iteration 140 , obj. function = 23.18439236186285\n",
            "Iteration 150 , obj. function = 23.045015823845084\n",
            "Iteration 160 , obj. function = 22.906555407550893\n",
            "Iteration 170 , obj. function = 22.769005091314067\n",
            "Iteration 180 , obj. function = 22.632358893048487\n",
            "Iteration 190 , obj. function = 22.496610869988505\n",
            "Iteration 200 , obj. function = 22.361755118430246\n",
            "Iteration 210 , obj. function = 22.227785773474658\n",
            "Iteration 220 , obj. function = 22.09469700877289\n",
            "Iteration 230 , obj. function = 21.9624830362726\n",
            "Iteration 240 , obj. function = 21.831138105966286\n",
            "Iteration 250 , obj. function = 21.700656505641142\n",
            "Iteration 260 , obj. function = 21.57103256063089\n",
            "Iteration 270 , obj. function = 21.442260633568683\n",
            "Iteration 280 , obj. function = 21.314335124142193\n",
            "Iteration 290 , obj. function = 21.187250468849747\n",
            "Iteration 300 , obj. function = 21.061001140758997\n",
            "Iteration 310 , obj. function = 20.93558164926571\n",
            "Iteration 320 , obj. function = 20.81098653985524\n",
            "Iteration 330 , obj. function = 20.687210393865918\n",
            "Iteration 340 , obj. function = 20.564247828252682\n",
            "Iteration 350 , obj. function = 20.44209349535313\n",
            "Iteration 360 , obj. function = 20.320742082655347\n",
            "Iteration 370 , obj. function = 20.200188312566116\n",
            "Iteration 380 , obj. function = 20.08042694218221\n",
            "Iteration 390 , obj. function = 19.96145276306188\n",
            "Iteration 400 , obj. function = 19.84326060099832\n",
            "Iteration 410 , obj. function = 19.725845315794984\n",
            "Iteration 420 , obj. function = 19.609201801041582\n",
            "Iteration 430 , obj. function = 19.49332498389235\n",
            "Iteration 440 , obj. function = 19.378209824845733\n",
            "Iteration 450 , obj. function = 19.26385131752414\n",
            "Iteration 460 , obj. function = 19.150244488457375\n",
            "Iteration 470 , obj. function = 19.037384396865363\n",
            "Iteration 480 , obj. function = 18.925266134444264\n",
            "Iteration 490 , obj. function = 18.81388482515247\n",
            "Iteration 500 , obj. function = 18.703235624998264\n",
            "Iteration 510 , obj. function = 18.59331372182963\n",
            "Iteration 520 , obj. function = 18.48411433512495\n",
            "Iteration 530 , obj. function = 18.375632715784853\n",
            "Iteration 540 , obj. function = 18.267864145925703\n",
            "Iteration 550 , obj. function = 18.160803938674682\n",
            "Iteration 560 , obj. function = 18.054447437965667\n",
            "Iteration 570 , obj. function = 17.94879001833686\n",
            "Iteration 580 , obj. function = 17.84382708472978\n",
            "Iteration 590 , obj. function = 17.73955407228874\n",
            "Iteration 600 , obj. function = 17.635966446163515\n",
            "Iteration 610 , obj. function = 17.533059701310993\n",
            "Iteration 620 , obj. function = 17.43082936229999\n",
            "Iteration 630 , obj. function = 17.329270983116036\n",
            "Iteration 640 , obj. function = 17.22838014696849\n",
            "Iteration 650 , obj. function = 17.128152466098243\n",
            "Iteration 660 , obj. function = 17.02858358158688\n",
            "Iteration 670 , obj. function = 16.92966916316712\n",
            "Iteration 680 , obj. function = 16.83140490903456\n",
            "Iteration 690 , obj. function = 16.73378654566073\n",
            "Iteration 700 , obj. function = 16.636809827606704\n",
            "Iteration 710 , obj. function = 16.540470537339054\n",
            "Iteration 720 , obj. function = 16.44476448504612\n",
            "Iteration 730 , obj. function = 16.34968750845602\n",
            "Iteration 740 , obj. function = 16.255235472654988\n",
            "Iteration 750 , obj. function = 16.161404269908722\n",
            "Iteration 760 , obj. function = 16.068189819482583\n",
            "Iteration 770 , obj. function = 15.975588067464702\n",
            "Iteration 780 , obj. function = 15.88359498658962\n",
            "Iteration 790 , obj. function = 15.792206576063029\n",
            "Iteration 800 , obj. function = 15.701418861387994\n",
            "Iteration 810 , obj. function = 15.611227894191574\n",
            "Iteration 820 , obj. function = 15.521629752053807\n",
            "Iteration 830 , obj. function = 15.432620538336854\n",
            "Iteration 840 , obj. function = 15.34419638201511\n",
            "Iteration 850 , obj. function = 15.256353437507453\n",
            "Iteration 860 , obj. function = 15.16908788450973\n",
            "Iteration 870 , obj. function = 15.082395927828669\n",
            "Iteration 880 , obj. function = 14.996273797216672\n",
            "Iteration 890 , obj. function = 14.910717747208077\n",
            "Iteration 900 , obj. function = 14.825724056956133\n",
            "Iteration 910 , obj. function = 14.741289030071297\n",
            "Iteration 920 , obj. function = 14.657408994460267\n",
            "Iteration 930 , obj. function = 14.574080302166312\n",
            "Iteration 940 , obj. function = 14.491299329211001\n",
            "Iteration 950 , obj. function = 14.409062475436135\n",
            "Iteration 960 , obj. function = 14.327366164347202\n",
            "Iteration 970 , obj. function = 14.24620684295819\n",
            "Iteration 980 , obj. function = 14.165580981637042\n",
            "Iteration 990 , obj. function = 14.085485073951364\n",
            "Iteration 1000 , obj. function = 14.005915636517294\n",
            "Iteration 1010 , obj. function = 13.92686920884632\n",
            "Iteration 1020 , obj. function = 13.848342353196774\n",
            "Iteration 1030 , obj. function = 13.770331654422494\n",
            "Iteration 1040 , obj. function = 13.692833719825344\n",
            "Iteration 1050 , obj. function = 13.615845179007332\n",
            "Iteration 1060 , obj. function = 13.539362683724121\n",
            "Iteration 1070 , obj. function = 13.463382907739291\n",
            "Iteration 1080 , obj. function = 13.387902546679923\n",
            "Iteration 1090 , obj. function = 13.31291831789262\n",
            "Iteration 1100 , obj. function = 13.238426960300913\n",
            "Iteration 1110 , obj. function = 13.1644252342633\n",
            "Iteration 1120 , obj. function = 13.090909921432457\n",
            "Iteration 1130 , obj. function = 13.017877824615491\n",
            "Iteration 1140 , obj. function = 12.945325767634106\n",
            "Iteration 1150 , obj. function = 12.873250595187626\n",
            "Iteration 1160 , obj. function = 12.801649172714823\n",
            "Iteration 1170 , obj. function = 12.730518386257941\n",
            "Iteration 1180 , obj. function = 12.65985514232745\n",
            "Iteration 1190 , obj. function = 12.58965636776718\n",
            "Iteration 1200 , obj. function = 12.519919009620653\n",
            "Iteration 1210 , obj. function = 12.450640034998862\n",
            "Iteration 1220 , obj. function = 12.381816430947634\n",
            "Iteration 1230 , obj. function = 12.31344520431715\n",
            "Iteration 1240 , obj. function = 12.245523381631338\n",
            "Iteration 1250 , obj. function = 12.178048008959063\n",
            "Iteration 1260 , obj. function = 12.111016151785106\n",
            "Iteration 1270 , obj. function = 12.044424894883042\n",
            "Iteration 1280 , obj. function = 11.97827134218799\n",
            "Iteration 1290 , obj. function = 11.912552616671086\n",
            "Iteration 1300 , obj. function = 11.847265860214033\n",
            "Iteration 1310 , obj. function = 11.782408233485052\n",
            "Iteration 1320 , obj. function = 11.717976915815223\n",
            "Iteration 1330 , obj. function = 11.653969105075895\n",
            "Iteration 1340 , obj. function = 11.590382017556886\n",
            "Iteration 1350 , obj. function = 11.527212887845206\n",
            "Iteration 1360 , obj. function = 11.46445896870494\n",
            "Iteration 1370 , obj. function = 11.402117530957733\n",
            "Iteration 1380 , obj. function = 11.340185863364301\n",
            "Iteration 1390 , obj. function = 11.278661272506138\n",
            "Iteration 1400 , obj. function = 11.217541082668546\n",
            "Iteration 1410 , obj. function = 11.156822635724469\n",
            "Iteration 1420 , obj. function = 11.096503291018546\n",
            "Iteration 1430 , obj. function = 11.036580425252534\n",
            "Iteration 1440 , obj. function = 10.977051432371148\n",
            "Iteration 1450 , obj. function = 10.917913723448601\n",
            "Iteration 1460 , obj. function = 10.85916472657621\n",
            "Iteration 1470 , obj. function = 10.800801886750358\n",
            "Iteration 1480 , obj. function = 10.742822665761528\n",
            "Iteration 1490 , obj. function = 10.685224542083802\n",
            "Iteration 1500 , obj. function = 10.628005010765259\n",
            "Iteration 1510 , obj. function = 10.57116158331904\n",
            "Iteration 1520 , obj. function = 10.514691787615089\n",
            "Iteration 1530 , obj. function = 10.45859316777269\n",
            "Iteration 1540 , obj. function = 10.402863284053558\n",
            "Iteration 1550 , obj. function = 10.347499712755841\n",
            "Iteration 1560 , obj. function = 10.292500046108767\n",
            "Iteration 1570 , obj. function = 10.237861892167652\n",
            "Iteration 1580 , obj. function = 10.183582874710169\n",
            "Iteration 1590 , obj. function = 10.12966063313296\n",
            "Iteration 1600 , obj. function = 10.076092822348734\n",
            "Iteration 1610 , obj. function = 10.022877112684544\n",
            "Iteration 1620 , obj. function = 9.97001118978055\n",
            "Iteration 1630 , obj. function = 9.917492754488855\n",
            "Iteration 1640 , obj. function = 9.865319522774097\n",
            "Iteration 1650 , obj. function = 9.813489225613806\n",
            "Iteration 1660 , obj. function = 9.76199960889982\n",
            "Iteration 1670 , obj. function = 9.71084843334017\n",
            "Iteration 1680 , obj. function = 9.660033474361777\n",
            "Iteration 1690 , obj. function = 9.609552522013733\n",
            "Iteration 1700 , obj. function = 9.559403380871025\n",
            "Iteration 1710 , obj. function = 9.50958386993925\n",
            "Iteration 1720 , obj. function = 9.460091822559614\n",
            "Iteration 1730 , obj. function = 9.410925086314876\n",
            "Iteration 1740 , obj. function = 9.362081522935462\n",
            "Iteration 1750 , obj. function = 9.313559008206807\n",
            "Iteration 1760 , obj. function = 9.265355431876678\n",
            "Iteration 1770 , obj. function = 9.217468697563628\n",
            "Iteration 1780 , obj. function = 9.169896722665642\n",
            "Iteration 1790 , obj. function = 9.122637438269647\n",
            "Iteration 1800 , obj. function = 9.075688789061601\n",
            "Iteration 1810 , obj. function = 9.029048733236962\n",
            "Iteration 1820 , obj. function = 8.982715242412059\n",
            "Iteration 1830 , obj. function = 8.936686301535657\n",
            "Iteration 1840 , obj. function = 8.890959908801543\n",
            "Iteration 1850 , obj. function = 8.845534075561329\n",
            "Iteration 1860 , obj. function = 8.800406826238007\n",
            "Iteration 1870 , obj. function = 8.755576198240101\n",
            "Iteration 1880 , obj. function = 8.711040241876148\n",
            "Iteration 1890 , obj. function = 8.66679702027009\n",
            "Iteration 1900 , obj. function = 8.622844609276893\n",
            "Iteration 1910 , obj. function = 8.579181097398953\n",
            "Iteration 1920 , obj. function = 8.535804585702914\n",
            "Iteration 1930 , obj. function = 8.492713187737042\n",
            "Iteration 1940 , obj. function = 8.449905029449516\n",
            "Iteration 1950 , obj. function = 8.407378249106246\n",
            "Iteration 1960 , obj. function = 8.365130997210624\n",
            "Iteration 1970 , obj. function = 8.323161436422723\n",
            "Iteration 1980 , obj. function = 8.281467741479387\n",
            "Iteration 1990 , obj. function = 8.240048099114901\n",
            "Iteration 2000 , obj. function = 8.198900707982226\n",
            "Iteration 2010 , obj. function = 8.158023778574488\n",
            "Iteration 2020 , obj. function = 8.11741553314729\n",
            "Iteration 2030 , obj. function = 8.077074205641287\n",
            "Iteration 2040 , obj. function = 8.036998041605544\n",
            "Iteration 2050 , obj. function = 7.9971852981210425\n",
            "Iteration 2060 , obj. function = 7.957634243725028\n",
            "Iteration 2070 , obj. function = 7.918343158335571\n",
            "Iteration 2080 , obj. function = 7.8793103331768695\n",
            "Iteration 2090 , obj. function = 7.840534070704923\n",
            "Iteration 2100 , obj. function = 7.802012684533652\n",
            "Iteration 2110 , obj. function = 7.763744499361626\n",
            "Iteration 2120 , obj. function = 7.72572785089918\n",
            "Iteration 2130 , obj. function = 7.687961085795962\n",
            "Iteration 2140 , obj. function = 7.6504425615691245\n",
            "Iteration 2150 , obj. function = 7.613170646531842\n",
            "Iteration 2160 , obj. function = 7.57614371972236\n",
            "Iteration 2170 , obj. function = 7.53936017083357\n",
            "Iteration 2180 , obj. function = 7.502818400142811\n",
            "Iteration 2190 , obj. function = 7.46651681844243\n",
            "Iteration 2200 , obj. function = 7.430453846970678\n",
            "Iteration 2210 , obj. function = 7.3946279173429135\n",
            "Iteration 2220 , obj. function = 7.3590374714836555\n",
            "Iteration 2230 , obj. function = 7.323680961558414\n",
            "Iteration 2240 , obj. function = 7.288556849906775\n",
            "Iteration 2250 , obj. function = 7.253663608975337\n",
            "Iteration 2260 , obj. function = 7.218999721251255\n",
            "Iteration 2270 , obj. function = 7.184563679196337\n",
            "Iteration 2280 , obj. function = 7.150353985181471\n",
            "Iteration 2290 , obj. function = 7.116369151421368\n",
            "Iteration 2300 , obj. function = 7.082607699910001\n",
            "Iteration 2310 , obj. function = 7.049068162356226\n",
            "Iteration 2320 , obj. function = 7.015749080120113\n",
            "Iteration 2330 , obj. function = 6.982649004149151\n",
            "Iteration 2340 , obj. function = 6.949766494915691\n",
            "Iteration 2350 , obj. function = 6.917100122353857\n",
            "Iteration 2360 , obj. function = 6.884648465797808\n",
            "Iteration 2370 , obj. function = 6.852410113919589\n",
            "Iteration 2380 , obj. function = 6.820383664667987\n",
            "Iteration 2390 , obj. function = 6.788567725207388\n",
            "Iteration 2400 , obj. function = 6.756960911857343\n",
            "Iteration 2410 , obj. function = 6.725561850032331\n",
            "Iteration 2420 , obj. function = 6.694369174181958\n",
            "Iteration 2430 , obj. function = 6.663381527731615\n",
            "Iteration 2440 , obj. function = 6.63259756302342\n",
            "Iteration 2450 , obj. function = 6.6020159412576644\n",
            "Iteration 2460 , obj. function = 6.571635332434569\n",
            "Iteration 2470 , obj. function = 6.541454415296434\n",
            "Iteration 2480 , obj. function = 6.511471877270204\n",
            "Iteration 2490 , obj. function = 6.481686414410338\n",
            "Iteration 2500 , obj. function = 6.452096731342142\n",
            "Iteration 2510 , obj. function = 6.42270154120537\n",
            "Iteration 2520 , obj. function = 6.393499565598384\n",
            "Iteration 2530 , obj. function = 6.364489534522461\n",
            "Iteration 2540 , obj. function = 6.335670186326532\n",
            "Iteration 2550 , obj. function = 6.307040267652382\n",
            "Iteration 2560 , obj. function = 6.27859853338011\n",
            "Iteration 2570 , obj. function = 6.250343746574049\n",
            "Iteration 2580 , obj. function = 6.222274678428769\n",
            "Iteration 2590 , obj. function = 6.194390108215956\n",
            "Iteration 2600 , obj. function = 6.166688823230983\n",
            "Iteration 2610 , obj. function = 6.139169618740371\n",
            "Iteration 2620 , obj. function = 6.111831297929419\n",
            "Iteration 2630 , obj. function = 6.084672671850017\n",
            "Iteration 2640 , obj. function = 6.057692559369014\n",
            "Iteration 2650 , obj. function = 6.0308897871168945\n",
            "Iteration 2660 , obj. function = 6.004263189436669\n",
            "Iteration 2670 , obj. function = 5.977811608333212\n",
            "Iteration 2680 , obj. function = 5.951533893422807\n",
            "Iteration 2690 , obj. function = 5.92542890188339\n",
            "Iteration 2700 , obj. function = 5.899495498404523\n",
            "Iteration 2710 , obj. function = 5.873732555138225\n",
            "Iteration 2720 , obj. function = 5.848138951649799\n",
            "Iteration 2730 , obj. function = 5.822713574869245\n",
            "Iteration 2740 , obj. function = 5.797455319042715\n",
            "Iteration 2750 , obj. function = 5.772363085684482\n",
            "Iteration 2760 , obj. function = 5.747435783529167\n",
            "Iteration 2770 , obj. function = 5.722672328484321\n",
            "Iteration 2780 , obj. function = 5.698071643583172\n",
            "Iteration 2790 , obj. function = 5.673632658937821\n",
            "Iteration 2800 , obj. function = 5.649354311692848\n",
            "Iteration 2810 , obj. function = 5.62523554597888\n",
            "Iteration 2820 , obj. function = 5.601275312866877\n",
            "Iteration 2830 , obj. function = 5.57747257032228\n",
            "Iteration 2840 , obj. function = 5.5538262831599265\n",
            "Iteration 2850 , obj. function = 5.530335422998814\n",
            "Iteration 2860 , obj. function = 5.5069989682176335\n",
            "Iteration 2870 , obj. function = 5.483815903910088\n",
            "Iteration 2880 , obj. function = 5.460785221840849\n",
            "Iteration 2890 , obj. function = 5.437905920401735\n",
            "Iteration 2900 , obj. function = 5.415177004568233\n",
            "Iteration 2910 , obj. function = 5.392597485855955\n",
            "Iteration 2920 , obj. function = 5.370166382277976\n",
            "Iteration 2930 , obj. function = 5.347882718301829\n",
            "Iteration 2940 , obj. function = 5.325745524807299\n",
            "Iteration 2950 , obj. function = 5.303753839044224\n",
            "Iteration 2960 , obj. function = 5.281906704590554\n",
            "Iteration 2970 , obj. function = 5.260203171310736\n",
            "Iteration 2980 , obj. function = 5.23864229531462\n",
            "Iteration 2990 , obj. function = 5.217223138916099\n",
            "Iteration 3000 , obj. function = 5.1959447705925115\n",
            "Iteration 3010 , obj. function = 5.17480626494409\n",
            "Iteration 3020 , obj. function = 5.153806702653747\n",
            "Iteration 3030 , obj. function = 5.132945170447091\n",
            "Iteration 3040 , obj. function = 5.112220761052573\n",
            "Iteration 3050 , obj. function = 5.091632573162223\n",
            "Iteration 3060 , obj. function = 5.071179711392442\n",
            "Iteration 3070 , obj. function = 5.0508612862447775\n",
            "Iteration 3080 , obj. function = 5.030676414067611\n",
            "Iteration 3090 , obj. function = 5.01062421701748\n",
            "Iteration 3100 , obj. function = 4.9907038230210725\n",
            "Iteration 3110 , obj. function = 4.9709143657371495\n",
            "Iteration 3120 , obj. function = 4.951254984518932\n",
            "Iteration 3130 , obj. function = 4.9317248243767\n",
            "Iteration 3140 , obj. function = 4.912323035940519\n",
            "Iteration 3150 , obj. function = 4.893048775423446\n",
            "Iteration 3160 , obj. function = 4.87390120458472\n",
            "Iteration 3170 , obj. function = 4.854879490693271\n",
            "Iteration 3180 , obj. function = 4.8359828064916375\n",
            "Iteration 3190 , obj. function = 4.817210330159946\n",
            "Iteration 3200 , obj. function = 4.798561245280068\n",
            "Iteration 3210 , obj. function = 4.780034740800229\n",
            "Iteration 3220 , obj. function = 4.7616300109996645\n",
            "Iteration 3230 , obj. function = 4.743346255453673\n",
            "Iteration 3240 , obj. function = 4.725182678998674\n",
            "Iteration 3250 , obj. function = 4.707138491697745\n",
            "Iteration 3260 , obj. function = 4.689212908806179\n",
            "Iteration 3270 , obj. function = 4.671405150737424\n",
            "Iteration 3280 , obj. function = 4.6537144430291555\n",
            "Iteration 3290 , obj. function = 4.636140016309563\n",
            "Iteration 3300 , obj. function = 4.618681106263914\n",
            "Iteration 3310 , obj. function = 4.601336953601322\n",
            "Iteration 3320 , obj. function = 4.584106804021764\n",
            "Iteration 3330 , obj. function = 4.566989908183164\n",
            "Iteration 3340 , obj. function = 4.549985521668894\n",
            "Iteration 3350 , obj. function = 4.533092904955381\n",
            "Iteration 3360 , obj. function = 4.5163113233799175\n",
            "Iteration 3370 , obj. function = 4.4996400471087625\n",
            "Iteration 3380 , obj. function = 4.48307835110533\n",
            "Iteration 3390 , obj. function = 4.466625515098759\n",
            "Iteration 3400 , obj. function = 4.450280823552477\n",
            "Iteration 3410 , obj. function = 4.4340435656331705\n",
            "Iteration 3420 , obj. function = 4.417913035179785\n",
            "Iteration 3430 , obj. function = 4.401888530672912\n",
            "Iteration 3440 , obj. function = 4.385969355204175\n",
            "Iteration 3450 , obj. function = 4.370154816446009\n",
            "Iteration 3460 , obj. function = 4.354444226621561\n",
            "Iteration 3470 , obj. function = 4.338836902474626\n",
            "Iteration 3480 , obj. function = 4.323332165240088\n",
            "Iteration 3490 , obj. function = 4.307929340614418\n",
            "Iteration 3500 , obj. function = 4.292627758726177\n",
            "Iteration 3510 , obj. function = 4.27742675410711\n",
            "Iteration 3520 , obj. function = 4.26232566566292\n",
            "Iteration 3530 , obj. function = 4.247323836644847\n",
            "Iteration 3540 , obj. function = 4.232420614620848\n",
            "Iteration 3550 , obj. function = 4.217615351447324\n",
            "Iteration 3560 , obj. function = 4.202907403240969\n",
            "Iteration 3570 , obj. function = 4.188296130350636\n",
            "Iteration 3580 , obj. function = 4.173780897329721\n",
            "Iteration 3590 , obj. function = 4.159361072908279\n",
            "Iteration 3600 , obj. function = 4.145036029965777\n",
            "Iteration 3610 , obj. function = 4.130805145503727\n",
            "Iteration 3620 , obj. function = 4.11666780061865\n",
            "Iteration 3630 , obj. function = 4.102623380475024\n",
            "Iteration 3640 , obj. function = 4.088671274278779\n",
            "Iteration 3650 , obj. function = 4.0748108752504315\n",
            "Iteration 3660 , obj. function = 4.061041580599012\n",
            "Iteration 3670 , obj. function = 4.0473627914955275\n",
            "Iteration 3680 , obj. function = 4.033773913047255\n",
            "Iteration 3690 , obj. function = 4.020274354271617\n",
            "Iteration 3700 , obj. function = 4.006863528070533\n",
            "Iteration 3710 , obj. function = 3.9935408512050112\n",
            "Iteration 3720 , obj. function = 3.980305744269596\n",
            "Iteration 3730 , obj. function = 3.9671576316673174\n",
            "Iteration 3740 , obj. function = 3.954095941584571\n",
            "Iteration 3750 , obj. function = 3.9411201059663146\n",
            "Iteration 3760 , obj. function = 3.928229560491307\n",
            "Iteration 3770 , obj. function = 3.91542374454756\n",
            "Iteration 3780 , obj. function = 3.902702101208106\n",
            "Iteration 3790 , obj. function = 3.890064077206497\n",
            "Iteration 3800 , obj. function = 3.877509122913021\n",
            "Iteration 3810 , obj. function = 3.8650366923106283\n",
            "Iteration 3820 , obj. function = 3.852646242971258\n",
            "Iteration 3830 , obj. function = 3.8403372360322185\n",
            "Iteration 3840 , obj. function = 3.8281091361727735\n",
            "Iteration 3850 , obj. function = 3.815961411590798\n",
            "Iteration 3860 , obj. function = 3.8038935339798052\n",
            "Iteration 3870 , obj. function = 3.7919049785057783\n",
            "Iteration 3880 , obj. function = 3.779995223784439\n",
            "Iteration 3890 , obj. function = 3.768163751858607\n",
            "Iteration 3900 , obj. function = 3.7564100481755913\n",
            "Iteration 3910 , obj. function = 3.7447336015649517\n",
            "Iteration 3920 , obj. function = 3.7331339042160243\n",
            "Iteration 3930 , obj. function = 3.7216104516560664\n",
            "Iteration 3940 , obj. function = 3.710162742728216\n",
            "Iteration 3950 , obj. function = 3.698790279569742\n",
            "Iteration 3960 , obj. function = 3.687492567590359\n",
            "Iteration 3970 , obj. function = 3.6762691154506792\n",
            "Iteration 3980 , obj. function = 3.665119435040909\n",
            "Iteration 3990 , obj. function = 3.6540430414596328\n",
            "Iteration 4000 , obj. function = 3.6430394529926335\n",
            "Iteration 4010 , obj. function = 3.6321081910920294\n",
            "Iteration 4020 , obj. function = 3.6212487803554905\n",
            "Iteration 4030 , obj. function = 3.61046074850537\n",
            "Iteration 4040 , obj. function = 3.5997436263684492\n",
            "Iteration 4050 , obj. function = 3.5890969478552597\n",
            "Iteration 4060 , obj. function = 3.5785202499400532\n",
            "Iteration 4070 , obj. function = 3.568013072640447\n",
            "Iteration 4080 , obj. function = 3.5575749589975683\n",
            "Iteration 4090 , obj. function = 3.5472054550561385\n",
            "Iteration 4100 , obj. function = 3.5369041098447442\n",
            "Iteration 4110 , obj. function = 3.526670475356139\n",
            "Iteration 4120 , obj. function = 3.5165041065278677\n",
            "Iteration 4130 , obj. function = 3.5064045612229116\n",
            "Iteration 4140 , obj. function = 3.496371400210351\n",
            "Iteration 4150 , obj. function = 3.4864041871463534\n",
            "Iteration 4160 , obj. function = 3.4765024885551865\n",
            "Iteration 4170 , obj. function = 3.466665873810308\n",
            "Iteration 4180 , obj. function = 3.4568939151157814\n",
            "Iteration 4190 , obj. function = 3.4471861874874685\n",
            "Iteration 4200 , obj. function = 3.4375422687346884\n",
            "Iteration 4210 , obj. function = 3.4279617394418294\n",
            "Iteration 4220 , obj. function = 3.4184441829501093\n",
            "Iteration 4230 , obj. function = 3.408989185339392\n",
            "Iteration 4240 , obj. function = 3.399596335410286\n",
            "Iteration 4250 , obj. function = 3.3902652246661944\n",
            "Iteration 4260 , obj. function = 3.380995447295579\n",
            "Iteration 4270 , obj. function = 3.3717866001542793\n",
            "Iteration 4280 , obj. function = 3.3626382827479944\n",
            "Iteration 4290 , obj. function = 3.353550097214926\n",
            "Iteration 4300 , obj. function = 3.344521648308372\n",
            "Iteration 4310 , obj. function = 3.3355525433796\n",
            "Iteration 4320 , obj. function = 3.326642392360735\n",
            "Iteration 4330 , obj. function = 3.3177908077478375\n",
            "Iteration 4340 , obj. function = 3.3089974045840482\n",
            "Iteration 4350 , obj. function = 3.3002618004428146\n",
            "Iteration 4360 , obj. function = 3.2915836154112568\n",
            "Iteration 4370 , obj. function = 3.2829624720736827\n",
            "Iteration 4380 , obj. function = 3.274397995495142\n",
            "Iteration 4390 , obj. function = 3.2658898132051117\n",
            "Iteration 4400 , obj. function = 3.2574375551813897\n",
            "Iteration 4410 , obj. function = 3.2490408538338347\n",
            "Iteration 4420 , obj. function = 3.240699343988532\n",
            "Iteration 4430 , obj. function = 3.2324126628718344\n",
            "Iteration 4440 , obj. function = 3.2241804500946096\n",
            "Iteration 4450 , obj. function = 3.216002347636592\n",
            "Iteration 4460 , obj. function = 3.2078779998307327\n",
            "Iteration 4470 , obj. function = 3.1998070533477785\n",
            "Iteration 4480 , obj. function = 3.1917891571809687\n",
            "Iteration 4490 , obj. function = 3.1838239626306852\n",
            "Iteration 4500 , obj. function = 3.1759111232892647\n",
            "Iteration 4510 , obj. function = 3.16805029502605\n",
            "Iteration 4520 , obj. function = 3.1602411359722753\n",
            "Iteration 4530 , obj. function = 3.1524833065063858\n",
            "Iteration 4540 , obj. function = 3.1447764692390496\n",
            "Iteration 4550 , obj. function = 3.1371202889986503\n",
            "Iteration 4560 , obj. function = 3.1295144328166558\n",
            "Iteration 4570 , obj. function = 3.1219585699131196\n",
            "Iteration 4580 , obj. function = 3.1144523716823267\n",
            "Iteration 4590 , obj. function = 3.106995511678466\n",
            "Iteration 4600 , obj. function = 3.0995876656014367\n",
            "Iteration 4610 , obj. function = 3.0922285112828227\n",
            "Iteration 4620 , obj. function = 3.0849177286717717\n",
            "Iteration 4630 , obj. function = 3.077654999821186\n",
            "Iteration 4640 , obj. function = 3.0704400088737103\n",
            "Iteration 4650 , obj. function = 3.063272442048249\n",
            "Iteration 4660 , obj. function = 3.0561519876261287\n",
            "Iteration 4670 , obj. function = 3.0490783359376\n",
            "Iteration 4680 , obj. function = 3.042051179348391\n",
            "Iteration 4690 , obj. function = 3.035070212246311\n",
            "Iteration 4700 , obj. function = 3.0281351310279065\n",
            "Iteration 4710 , obj. function = 3.0212456340854086\n",
            "Iteration 4720 , obj. function = 3.014401421793396\n",
            "Iteration 4730 , obj. function = 3.007602196495996\n",
            "Iteration 4740 , obj. function = 3.0008476624937734\n",
            "Iteration 4750 , obj. function = 2.994137526030877\n",
            "Iteration 4760 , obj. function = 2.9874714952824193\n",
            "Iteration 4770 , obj. function = 2.980849280341598\n",
            "Iteration 4780 , obj. function = 2.974270593207212\n",
            "Iteration 4790 , obj. function = 2.967735147771024\n",
            "Iteration 4800 , obj. function = 2.9612426598054857\n",
            "Iteration 4810 , obj. function = 2.9547928469511846\n",
            "Iteration 4820 , obj. function = 2.948385428704723\n",
            "Iteration 4830 , obj. function = 2.9420201264064114\n",
            "Iteration 4840 , obj. function = 2.9356966632281876\n",
            "Iteration 4850 , obj. function = 2.9294147641616224\n",
            "Iteration 4860 , obj. function = 2.923174156005855\n",
            "Iteration 4870 , obj. function = 2.9169745673558345\n",
            "Iteration 4880 , obj. function = 2.9108157285904066\n",
            "Iteration 4890 , obj. function = 2.9046973718606526\n",
            "Iteration 4900 , obj. function = 2.8986192310782593\n",
            "Iteration 4910 , obj. function = 2.892581041903862\n",
            "Iteration 4920 , obj. function = 2.8865825417356037\n",
            "Iteration 4930 , obj. function = 2.880623469697726\n",
            "Iteration 4940 , obj. function = 2.8747035666292033\n",
            "Iteration 4950 , obj. function = 2.868822575072501\n",
            "Iteration 4960 , obj. function = 2.862980239262284\n",
            "Iteration 4970 , obj. function = 2.857176305114412\n",
            "Iteration 4980 , obj. function = 2.851410520214843\n",
            "Iteration 4990 , obj. function = 2.8456826338086523\n",
            "Iteration 5000 , obj. function = 2.8399923967890808\n",
            "Iteration 5010 , obj. function = 2.8343395616867726\n",
            "Iteration 5020 , obj. function = 2.828723882659049\n",
            "Iteration 5030 , obj. function = 2.8231451154790683\n",
            "Iteration 5040 , obj. function = 2.817603017525299\n",
            "Iteration 5050 , obj. function = 2.8120973477710316\n",
            "Iteration 5060 , obj. function = 2.806627866773768\n",
            "Iteration 5070 , obj. function = 2.801194336664859\n",
            "Iteration 5080 , obj. function = 2.795796521139186\n",
            "Iteration 5090 , obj. function = 2.7904341854448824\n",
            "Iteration 5100 , obj. function = 2.7851070963730686\n",
            "Iteration 5110 , obj. function = 2.779815022247738\n",
            "Iteration 5120 , obj. function = 2.774557732915759\n",
            "Iteration 5130 , obj. function = 2.769334999736703\n",
            "Iteration 5140 , obj. function = 2.764146595573077\n",
            "Iteration 5150 , obj. function = 2.7589922947803096\n",
            "Iteration 5160 , obj. function = 2.7538718731970118\n",
            "Iteration 5170 , obj. function = 2.7487851081351926\n",
            "Iteration 5180 , obj. function = 2.743731778370634\n",
            "Iteration 5190 , obj. function = 2.738711664133148\n",
            "Iteration 5200 , obj. function = 2.7337245470971623\n",
            "Iteration 5210 , obj. function = 2.728770210372116\n",
            "Iteration 5220 , obj. function = 2.723848438493092\n",
            "Iteration 5230 , obj. function = 2.718959017411443\n",
            "Iteration 5240 , obj. function = 2.7141017344853857\n",
            "Iteration 5250 , obj. function = 2.7092763784709537\n",
            "Iteration 5260 , obj. function = 2.704482739512555\n",
            "Iteration 5270 , obj. function = 2.699720609134057\n",
            "Iteration 5280 , obj. function = 2.6949897802296543\n",
            "Iteration 5290 , obj. function = 2.690290047054777\n",
            "Iteration 5300 , obj. function = 2.6856212052172705\n",
            "Iteration 5310 , obj. function = 2.680983051668438\n",
            "Iteration 5320 , obj. function = 2.67637538469418\n",
            "Iteration 5330 , obj. function = 2.6717980039063502\n",
            "Iteration 5340 , obj. function = 2.667250710233871\n",
            "Iteration 5350 , obj. function = 2.662733305914177\n",
            "Iteration 5360 , obj. function = 2.6582455944846526\n",
            "Iteration 5370 , obj. function = 2.653787380773941\n",
            "Iteration 5380 , obj. function = 2.649358470893629\n",
            "Iteration 5390 , obj. function = 2.644958672229646\n",
            "Iteration 5400 , obj. function = 2.640587793434072\n",
            "Iteration 5410 , obj. function = 2.6362456444166487\n",
            "Iteration 5420 , obj. function = 2.631932036336596\n",
            "Iteration 5430 , obj. function = 2.627646781594361\n",
            "Iteration 5440 , obj. function = 2.623389693823568\n",
            "Iteration 5450 , obj. function = 2.6191605878827047\n",
            "Iteration 5460 , obj. function = 2.614959279847283\n",
            "Iteration 5470 , obj. function = 2.6107855870017134\n",
            "Iteration 5480 , obj. function = 2.60663932783141\n",
            "Iteration 5490 , obj. function = 2.60252032201489\n",
            "Iteration 5500 , obj. function = 2.5984283904159047\n",
            "Iteration 5510 , obj. function = 2.594363355075645\n",
            "Iteration 5520 , obj. function = 2.5903250392050805\n",
            "Iteration 5530 , obj. function = 2.5863132671771796\n",
            "Iteration 5540 , obj. function = 2.5823278645193066\n",
            "Iteration 5550 , obj. function = 2.5783686579056684\n",
            "Iteration 5560 , obj. function = 2.5744354751496776\n",
            "Iteration 5570 , obj. function = 2.5705281451966\n",
            "Iteration 5580 , obj. function = 2.566646498115999\n",
            "Iteration 5590 , obj. function = 2.562790365094376\n",
            "Iteration 5600 , obj. function = 2.558959578427915\n",
            "Iteration 5610 , obj. function = 2.5551539715150215\n",
            "Iteration 5620 , obj. function = 2.5513733788492665\n",
            "Iteration 5630 , obj. function = 2.5476176360120144\n",
            "Iteration 5640 , obj. function = 2.54388657966544\n",
            "Iteration 5650 , obj. function = 2.540180047545216\n",
            "Iteration 5660 , obj. function = 2.5364978784536953\n",
            "Iteration 5670 , obj. function = 2.5328399122527334\n",
            "Iteration 5680 , obj. function = 2.5292059898567594\n",
            "Iteration 5690 , obj. function = 2.5255959532259076\n",
            "Iteration 5700 , obj. function = 2.5220096453590566\n",
            "Iteration 5710 , obj. function = 2.5184469102871274\n",
            "Iteration 5720 , obj. function = 2.514907593066139\n",
            "Iteration 5730 , obj. function = 2.5113915397706394\n",
            "Iteration 5740 , obj. function = 2.507898597486884\n",
            "Iteration 5750 , obj. function = 2.504428614306213\n",
            "Iteration 5760 , obj. function = 2.500981439318505\n",
            "Iteration 5770 , obj. function = 2.497556922605531\n",
            "Iteration 5780 , obj. function = 2.4941549152345077\n",
            "Iteration 5790 , obj. function = 2.4907752692515874\n",
            "Iteration 5800 , obj. function = 2.4874178376753617\n",
            "Iteration 5810 , obj. function = 2.484082474490638\n",
            "Iteration 5820 , obj. function = 2.4807690346418765\n",
            "Iteration 5830 , obj. function = 2.477477374027045\n",
            "Iteration 5840 , obj. function = 2.4742073494912655\n",
            "Iteration 5850 , obj. function = 2.4709588188206753\n",
            "Iteration 5860 , obj. function = 2.4677316407360546\n",
            "Iteration 5870 , obj. function = 2.4645256748869913\n",
            "Iteration 5880 , obj. function = 2.461340781845443\n",
            "Iteration 5890 , obj. function = 2.4581768230998904\n",
            "Iteration 5900 , obj. function = 2.455033661049278\n",
            "Iteration 5910 , obj. function = 2.451911158996928\n",
            "Iteration 5920 , obj. function = 2.448809181144733\n",
            "Iteration 5930 , obj. function = 2.445727592587152\n",
            "Iteration 5940 , obj. function = 2.4426662593053816\n",
            "Iteration 5950 , obj. function = 2.4396250481615693\n",
            "Iteration 5960 , obj. function = 2.436603826892911\n",
            "Iteration 5970 , obj. function = 2.4336024641060052\n",
            "Iteration 5980 , obj. function = 2.430620829271066\n",
            "Iteration 5990 , obj. function = 2.4276587927163273\n",
            "Iteration 6000 , obj. function = 2.42471622562233\n",
            "Iteration 6010 , obj. function = 2.4217930000163412\n",
            "Iteration 6020 , obj. function = 2.41888898876677\n",
            "Iteration 6030 , obj. function = 2.416004065577725\n",
            "Iteration 6040 , obj. function = 2.413138104983404\n",
            "Iteration 6050 , obj. function = 2.41029098234272\n",
            "Iteration 6060 , obj. function = 2.4074625738338136\n",
            "Iteration 6070 , obj. function = 2.404652756448757\n",
            "Iteration 6080 , obj. function = 2.401861407988109\n",
            "Iteration 6090 , obj. function = 2.3990884070556593\n",
            "Iteration 6100 , obj. function = 2.3963336330531524\n",
            "Iteration 6110 , obj. function = 2.393596966175033\n",
            "Iteration 6120 , obj. function = 2.3908782874031678\n",
            "Iteration 6130 , obj. function = 2.388177478501804\n",
            "Iteration 6140 , obj. function = 2.3854944220122727\n",
            "Iteration 6150 , obj. function = 2.382829001248024\n",
            "Iteration 6160 , obj. function = 2.380181100289509\n",
            "Iteration 6170 , obj. function = 2.377550603979019\n",
            "Iteration 6180 , obj. function = 2.374937397915869\n",
            "Iteration 6190 , obj. function = 2.3723413684512544\n",
            "Iteration 6200 , obj. function = 2.369762402683479\n",
            "Iteration 6210 , obj. function = 2.367200388452864\n",
            "Iteration 6220 , obj. function = 2.3646552143369974\n",
            "Iteration 6230 , obj. function = 2.3621267696458386\n",
            "Iteration 6240 , obj. function = 2.3596149444169097\n",
            "Iteration 6250 , obj. function = 2.3571196294104912\n",
            "Iteration 6260 , obj. function = 2.354640716104951\n",
            "Iteration 6270 , obj. function = 2.3521780966919312\n",
            "Iteration 6280 , obj. function = 2.3497316640717107\n",
            "Iteration 6290 , obj. function = 2.3473013118485246\n",
            "Iteration 6300 , obj. function = 2.344886934325955\n",
            "Iteration 6310 , obj. function = 2.34248842650233\n",
            "Iteration 6320 , obj. function = 2.3401056840661427\n",
            "Iteration 6330 , obj. function = 2.3377386033915317\n",
            "Iteration 6340 , obj. function = 2.3353870815337445\n",
            "Iteration 6350 , obj. function = 2.3330510162247617\n",
            "Iteration 6360 , obj. function = 2.3307303058686752\n",
            "Iteration 6370 , obj. function = 2.3284248495374045\n",
            "Iteration 6380 , obj. function = 2.3261345469663035\n",
            "Iteration 6390 , obj. function = 2.3238592985497246\n",
            "Iteration 6400 , obj. function = 2.321599005336715\n",
            "Iteration 6410 , obj. function = 2.3193535690267546\n",
            "Iteration 6420 , obj. function = 2.3171228919654743\n",
            "Iteration 6430 , obj. function = 2.3149068771403574\n",
            "Iteration 6440 , obj. function = 2.312705428176532\n",
            "Iteration 6450 , obj. function = 2.310518449332635\n",
            "Iteration 6460 , obj. function = 2.3083458454965786\n",
            "Iteration 6470 , obj. function = 2.3061875221814665\n",
            "Iteration 6480 , obj. function = 2.3040433855214797\n",
            "Iteration 6490 , obj. function = 2.3019133422677447\n",
            "Iteration 6500 , obj. function = 2.2997972997843226\n",
            "Iteration 6510 , obj. function = 2.297695166044207\n",
            "Iteration 6520 , obj. function = 2.2956068496252033\n",
            "Iteration 6530 , obj. function = 2.293532259706139\n",
            "Iteration 6540 , obj. function = 2.291471306062725\n",
            "Iteration 6550 , obj. function = 2.2894238990637525\n",
            "Iteration 6560 , obj. function = 2.28738994966716\n",
            "Iteration 6570 , obj. function = 2.285369369416131\n",
            "Iteration 6580 , obj. function = 2.283362070435336\n",
            "Iteration 6590 , obj. function = 2.2813679654269783\n",
            "Iteration 6600 , obj. function = 2.279386967667103\n",
            "Iteration 6610 , obj. function = 2.277418991001808\n",
            "Iteration 6620 , obj. function = 2.275463949843452\n",
            "Iteration 6630 , obj. function = 2.2735217591669485\n",
            "Iteration 6640 , obj. function = 2.2715923345061664\n",
            "Iteration 6650 , obj. function = 2.269675591950047\n",
            "Iteration 6660 , obj. function = 2.267771448139182\n",
            "Iteration 6670 , obj. function = 2.2658798202620165\n",
            "Iteration 6680 , obj. function = 2.264000626051331\n",
            "Iteration 6690 , obj. function = 2.2621337837806985\n",
            "Iteration 6700 , obj. function = 2.2602792122608006\n",
            "Iteration 6710 , obj. function = 2.2584368308360445\n",
            "Iteration 6720 , obj. function = 2.256606559380951\n",
            "Iteration 6730 , obj. function = 2.254788318296708\n",
            "Iteration 6740 , obj. function = 2.252982028507705\n",
            "Iteration 6750 , obj. function = 2.251187611458103\n",
            "Iteration 6760 , obj. function = 2.2494049891084282\n",
            "Iteration 6770 , obj. function = 2.247634083932103\n",
            "Iteration 6780 , obj. function = 2.2458748189122093\n",
            "Iteration 6790 , obj. function = 2.244127117537988\n",
            "Iteration 6800 , obj. function = 2.242390903801641\n",
            "Iteration 6810 , obj. function = 2.2406661021949015\n",
            "Iteration 6820 , obj. function = 2.2389526377059346\n",
            "Iteration 6830 , obj. function = 2.237250435815834\n",
            "Iteration 6840 , obj. function = 2.2355594224955766\n",
            "Iteration 6850 , obj. function = 2.233879524202712\n",
            "Iteration 6860 , obj. function = 2.232210667878175\n",
            "Iteration 6870 , obj. function = 2.23055278094316\n",
            "Iteration 6880 , obj. function = 2.228905791295835\n",
            "Iteration 6890 , obj. function = 2.2272696273083907\n",
            "Iteration 6900 , obj. function = 2.2256442178237927\n",
            "Iteration 6910 , obj. function = 2.2240294921526758\n",
            "Iteration 6920 , obj. function = 2.222425380070387\n",
            "Iteration 6930 , obj. function = 2.2208318118138095\n",
            "Iteration 6940 , obj. function = 2.2192487180784215\n",
            "Iteration 6950 , obj. function = 2.2176760300151668\n",
            "Iteration 6960 , obj. function = 2.2161136792276293\n",
            "Iteration 6970 , obj. function = 2.214561597768879\n",
            "Iteration 6980 , obj. function = 2.213019718138668\n",
            "Iteration 6990 , obj. function = 2.211487973280378\n",
            "Iteration 7000 , obj. function = 2.2099662965781723\n",
            "Iteration 7010 , obj. function = 2.2084546218540857\n",
            "Iteration 7020 , obj. function = 2.206952883365129\n",
            "Iteration 7030 , obj. function = 2.205461015800456\n",
            "Iteration 7040 , obj. function = 2.2039789542784916\n",
            "Iteration 7050 , obj. function = 2.2025066343441613\n",
            "Iteration 7060 , obj. function = 2.201043991965977\n",
            "Iteration 7070 , obj. function = 2.1995909635334203\n",
            "Iteration 7080 , obj. function = 2.198147485854034\n",
            "Iteration 7090 , obj. function = 2.1967134961507115\n",
            "Iteration 7100 , obj. function = 2.195288932059056\n",
            "Iteration 7110 , obj. function = 2.193873731624489\n",
            "Iteration 7120 , obj. function = 2.1924678332997547\n",
            "Iteration 7130 , obj. function = 2.191071175942065\n",
            "Iteration 7140 , obj. function = 2.1896836988105597\n",
            "Iteration 7150 , obj. function = 2.1883053415636686\n",
            "Iteration 7160 , obj. function = 2.1869360442563734\n",
            "Iteration 7170 , obj. function = 2.185575747337732\n",
            "Iteration 7180 , obj. function = 2.1842243916481867\n",
            "Iteration 7190 , obj. function = 2.1828819184170314\n",
            "Iteration 7200 , obj. function = 2.1815482692599435\n",
            "Iteration 7210 , obj. function = 2.180223386176273\n",
            "Iteration 7220 , obj. function = 2.1789072115466097\n",
            "Iteration 7230 , obj. function = 2.177599688130343\n",
            "Iteration 7240 , obj. function = 2.1763007590630385\n",
            "Iteration 7250 , obj. function = 2.1750103678540604\n",
            "Iteration 7260 , obj. function = 2.173728458384101\n",
            "Iteration 7270 , obj. function = 2.1724549749026805\n",
            "Iteration 7280 , obj. function = 2.171189862025789\n",
            "Iteration 7290 , obj. function = 2.169933064733495\n",
            "Iteration 7300 , obj. function = 2.1686845283674425\n",
            "Iteration 7310 , obj. function = 2.1674441986285746\n",
            "Iteration 7320 , obj. function = 2.166212021574783\n",
            "Iteration 7330 , obj. function = 2.1649879436184367\n",
            "Iteration 7340 , obj. function = 2.163771911524239\n",
            "Iteration 7350 , obj. function = 2.162563872406702\n",
            "Iteration 7360 , obj. function = 2.161363773728012\n",
            "Iteration 7370 , obj. function = 2.1601715632957084\n",
            "Iteration 7380 , obj. function = 2.1589871892603534\n",
            "Iteration 7390 , obj. function = 2.157810600113299\n",
            "Iteration 7400 , obj. function = 2.156641744684527\n",
            "Iteration 7410 , obj. function = 2.1554805721402865\n",
            "Iteration 7420 , obj. function = 2.1543270319810146\n",
            "Iteration 7430 , obj. function = 2.153181074039053\n",
            "Iteration 7440 , obj. function = 2.1520426484764967\n",
            "Iteration 7450 , obj. function = 2.1509117057830385\n",
            "Iteration 7460 , obj. function = 2.1497881967737786\n",
            "Iteration 7470 , obj. function = 2.1486720725871336\n",
            "Iteration 7480 , obj. function = 2.1475632846827017\n",
            "Iteration 7490 , obj. function = 2.146461784839075\n",
            "Iteration 7500 , obj. function = 2.145367525151852\n",
            "Iteration 7510 , obj. function = 2.1442804580315262\n",
            "Iteration 7520 , obj. function = 2.1432005362013404\n",
            "Iteration 7530 , obj. function = 2.142127712695325\n",
            "Iteration 7540 , obj. function = 2.1410619408562024\n",
            "Iteration 7550 , obj. function = 2.140003174333392\n",
            "Iteration 7560 , obj. function = 2.138951367080957\n",
            "Iteration 7570 , obj. function = 2.1379064733556135\n",
            "Iteration 7580 , obj. function = 2.1368684477147846\n",
            "Iteration 7590 , obj. function = 2.1358372450145446\n",
            "Iteration 7600 , obj. function = 2.1348128204077215\n",
            "Iteration 7610 , obj. function = 2.1337951293419213\n",
            "Iteration 7620 , obj. function = 2.1327841275575983\n",
            "Iteration 7630 , obj. function = 2.131779771086113\n",
            "Iteration 7640 , obj. function = 2.1307820162478333\n",
            "Iteration 7650 , obj. function = 2.1297908196502537\n",
            "Iteration 7660 , obj. function = 2.128806138186049\n",
            "Iteration 7670 , obj. function = 2.1278279290312634\n",
            "Iteration 7680 , obj. function = 2.1268561496434035\n",
            "Iteration 7690 , obj. function = 2.125890757759668\n",
            "Iteration 7700 , obj. function = 2.1249317113949666\n",
            "Iteration 7710 , obj. function = 2.1239789688402326\n",
            "Iteration 7720 , obj. function = 2.1230324886605225\n",
            "Iteration 7730 , obj. function = 2.1220922296932776\n",
            "Iteration 7740 , obj. function = 2.1211581510464534\n",
            "Iteration 7750 , obj. function = 2.120230212096827\n",
            "Iteration 7760 , obj. function = 2.1193083724881756\n",
            "Iteration 7770 , obj. function = 2.1183925921295566\n",
            "Iteration 7780 , obj. function = 2.1174828311935268\n",
            "Iteration 7790 , obj. function = 2.1165790501143977\n",
            "Iteration 7800 , obj. function = 2.1156812095866484\n",
            "Iteration 7810 , obj. function = 2.1147892705629925\n",
            "Iteration 7820 , obj. function = 2.113903194252865\n",
            "Iteration 7830 , obj. function = 2.1130229421206868\n",
            "Iteration 7840 , obj. function = 2.1121484758841067\n",
            "Iteration 7850 , obj. function = 2.1112797575124773\n",
            "Iteration 7860 , obj. function = 2.110416749225057\n",
            "Iteration 7870 , obj. function = 2.109559413489525\n",
            "Iteration 7880 , obj. function = 2.1087077130201552\n",
            "Iteration 7890 , obj. function = 2.1078616107763906\n",
            "Iteration 7900 , obj. function = 2.107021069961097\n",
            "Iteration 7910 , obj. function = 2.1061860540190063\n",
            "Iteration 7920 , obj. function = 2.1053565266351466\n",
            "Iteration 7930 , obj. function = 2.1045324517332014\n",
            "Iteration 7940 , obj. function = 2.1037137934740793\n",
            "Iteration 7950 , obj. function = 2.1029005162541408\n",
            "Iteration 7960 , obj. function = 2.1020925847038505\n",
            "Iteration 7970 , obj. function = 2.1012899636861273\n",
            "Iteration 7980 , obj. function = 2.100492618294878\n",
            "Iteration 7990 , obj. function = 2.099700513853362\n",
            "Iteration 8000 , obj. function = 2.0989136159128767\n",
            "Iteration 8010 , obj. function = 2.0981318902510653\n",
            "Iteration 8020 , obj. function = 2.0973553028705685\n",
            "Iteration 8030 , obj. function = 2.0965838199974898\n",
            "Iteration 8040 , obj. function = 2.09581740807988\n",
            "Iteration 8050 , obj. function = 2.0950560337863755\n",
            "Iteration 8060 , obj. function = 2.094299664004672\n",
            "Iteration 8070 , obj. function = 2.0935482658401363\n",
            "Iteration 8080 , obj. function = 2.0928018066143386\n",
            "Iteration 8090 , obj. function = 2.09206025386362\n",
            "Iteration 8100 , obj. function = 2.0913235753377517\n",
            "Iteration 8110 , obj. function = 2.09059173899844\n",
            "Iteration 8120 , obj. function = 2.0898647130180388\n",
            "Iteration 8130 , obj. function = 2.089142465778037\n",
            "Iteration 8140 , obj. function = 2.0884249658677847\n",
            "Iteration 8150 , obj. function = 2.087712182083116\n",
            "Iteration 8160 , obj. function = 2.087004083424937\n",
            "Iteration 8170 , obj. function = 2.0863006390978933\n",
            "Iteration 8180 , obj. function = 2.0856018185090988\n",
            "Iteration 8190 , obj. function = 2.0849075912667363\n",
            "Iteration 8200 , obj. function = 2.0842179271787282\n",
            "Iteration 8210 , obj. function = 2.0835327962514936\n",
            "Iteration 8220 , obj. function = 2.082852168688569\n",
            "Iteration 8230 , obj. function = 2.082176014889319\n",
            "Iteration 8240 , obj. function = 2.0815043054477327\n",
            "Iteration 8250 , obj. function = 2.0808370111510475\n",
            "Iteration 8260 , obj. function = 2.0801741029785537\n",
            "Iteration 8270 , obj. function = 2.07951555210021\n",
            "Iteration 8280 , obj. function = 2.0788613298755707\n",
            "Iteration 8290 , obj. function = 2.0782114078523684\n",
            "Iteration 8300 , obj. function = 2.077565757765427\n",
            "Iteration 8310 , obj. function = 2.0769243515353017\n",
            "Iteration 8320 , obj. function = 2.0762871612671203\n",
            "Iteration 8330 , obj. function = 2.0756541592493876\n",
            "Iteration 8340 , obj. function = 2.075025317952725\n",
            "Iteration 8350 , obj. function = 2.0744006100287287\n",
            "Iteration 8360 , obj. function = 2.073780008308767\n",
            "Iteration 8370 , obj. function = 2.073163485802729\n",
            "Iteration 8380 , obj. function = 2.0725510156979716\n",
            "Iteration 8390 , obj. function = 2.0719425713580746\n",
            "Iteration 8400 , obj. function = 2.071338126321674\n",
            "Iteration 8410 , obj. function = 2.0707376543013853\n",
            "Iteration 8420 , obj. function = 2.07014112918255\n",
            "Iteration 8430 , obj. function = 2.069548525022201\n",
            "Iteration 8440 , obj. function = 2.0689598160478986\n",
            "Iteration 8450 , obj. function = 2.0683749766565818\n",
            "Iteration 8460 , obj. function = 2.067793981413488\n",
            "Iteration 8470 , obj. function = 2.06721680505104\n",
            "Iteration 8480 , obj. function = 2.066643422467734\n",
            "Iteration 8490 , obj. function = 2.0660738087270984\n",
            "Iteration 8500 , obj. function = 2.065507939056496\n",
            "Iteration 8510 , obj. function = 2.0649457888461837\n",
            "Iteration 8520 , obj. function = 2.064387333648156\n",
            "Iteration 8530 , obj. function = 2.0638325491751006\n",
            "Iteration 8540 , obj. function = 2.0632814112993407\n",
            "Iteration 8550 , obj. function = 2.0627338960518222\n",
            "Iteration 8560 , obj. function = 2.0621899796209853\n",
            "Iteration 8570 , obj. function = 2.0616496383518403\n",
            "Iteration 8580 , obj. function = 2.0611128487448496\n",
            "Iteration 8590 , obj. function = 2.06057958745494\n",
            "Iteration 8600 , obj. function = 2.0600498312904763\n",
            "Iteration 8610 , obj. function = 2.0595235572123083\n",
            "Iteration 8620 , obj. function = 2.059000742332663\n",
            "Iteration 8630 , obj. function = 2.058481363914248\n",
            "Iteration 8640 , obj. function = 2.0579653993692117\n",
            "Iteration 8650 , obj. function = 2.057452826258162\n",
            "Iteration 8660 , obj. function = 2.056943622289182\n",
            "Iteration 8670 , obj. function = 2.0564377653169696\n",
            "Iteration 8680 , obj. function = 2.0559352333416956\n",
            "Iteration 8690 , obj. function = 2.0554360045081443\n",
            "Iteration 8700 , obj. function = 2.054940057104767\n",
            "Iteration 8710 , obj. function = 2.054447369562757\n",
            "Iteration 8720 , obj. function = 2.053957920455035\n",
            "Iteration 8730 , obj. function = 2.053471688495393\n",
            "Iteration 8740 , obj. function = 2.0529886525375036\n",
            "Iteration 8750 , obj. function = 2.05250879157407\n",
            "Iteration 8760 , obj. function = 2.052032084735856\n",
            "Iteration 8770 , obj. function = 2.051558511290781\n",
            "Iteration 8780 , obj. function = 2.0510880506430733\n",
            "Iteration 8790 , obj. function = 2.050620682332325\n",
            "Iteration 8800 , obj. function = 2.050156386032625\n",
            "Iteration 8810 , obj. function = 2.0496951415516387\n",
            "Iteration 8820 , obj. function = 2.0492369288297496\n",
            "Iteration 8830 , obj. function = 2.0487817279392178\n",
            "Iteration 8840 , obj. function = 2.048329519083293\n",
            "Iteration 8850 , obj. function = 2.0478802825953197\n",
            "Iteration 8860 , obj. function = 2.0474339989379757\n",
            "Iteration 8870 , obj. function = 2.046990648702257\n",
            "Iteration 8880 , obj. function = 2.0465502126067974\n",
            "Iteration 8890 , obj. function = 2.0461126714969837\n",
            "Iteration 8900 , obj. function = 2.0456780063440565\n",
            "Iteration 8910 , obj. function = 2.0452461982443713\n",
            "Iteration 8920 , obj. function = 2.0448172284185255\n",
            "Iteration 8930 , obj. function = 2.0443910782105323\n",
            "Iteration 8940 , obj. function = 2.0439677290870617\n",
            "Iteration 8950 , obj. function = 2.0435471626365906\n",
            "Iteration 8960 , obj. function = 2.043129360568624\n",
            "Iteration 8970 , obj. function = 2.0427143047128338\n",
            "Iteration 8980 , obj. function = 2.0423019770184365\n",
            "Iteration 8990 , obj. function = 2.0418923595531786\n",
            "Iteration 9000 , obj. function = 2.041485434502788\n",
            "Iteration 9010 , obj. function = 2.0410811841699807\n",
            "Iteration 9020 , obj. function = 2.0406795909738253\n",
            "Iteration 9030 , obj. function = 2.040280637449032\n",
            "Iteration 9040 , obj. function = 2.0398843062449976\n",
            "Iteration 9050 , obj. function = 2.0394905801252365\n",
            "Iteration 9060 , obj. function = 2.0390994419665063\n",
            "Iteration 9070 , obj. function = 2.0387108747581792\n",
            "Iteration 9080 , obj. function = 2.03832486160136\n",
            "Iteration 9090 , obj. function = 2.037941385708316\n",
            "Iteration 9100 , obj. function = 2.0375604304016197\n",
            "Iteration 9110 , obj. function = 2.037181979113409\n",
            "Iteration 9120 , obj. function = 2.03680601538482\n",
            "Iteration 9130 , obj. function = 2.036432522865113\n",
            "Iteration 9140 , obj. function = 2.0360614853110497\n",
            "Iteration 9150 , obj. function = 2.0356928865861192\n",
            "Iteration 9160 , obj. function = 2.035326710659924\n",
            "Iteration 9170 , obj. function = 2.034962941607417\n",
            "Iteration 9180 , obj. function = 2.0346015636081978\n",
            "Iteration 9190 , obj. function = 2.0342425609458967\n",
            "Iteration 9200 , obj. function = 2.0338859180074365\n",
            "Iteration 9210 , obj. function = 2.0335316192823143\n",
            "Iteration 9220 , obj. function = 2.0331796493620833\n",
            "Iteration 9230 , obj. function = 2.032829992939459\n",
            "Iteration 9240 , obj. function = 2.0324826348078524\n",
            "Iteration 9250 , obj. function = 2.032137559860587\n",
            "Iteration 9260 , obj. function = 2.0317947530903093\n",
            "Iteration 9270 , obj. function = 2.031454199588299\n",
            "Iteration 9280 , obj. function = 2.0311158845438158\n",
            "Iteration 9290 , obj. function = 2.030779793243482\n",
            "Iteration 9300 , obj. function = 2.030445911070638\n",
            "Iteration 9310 , obj. function = 2.0301142235046985\n",
            "Iteration 9320 , obj. function = 2.029784716120503\n",
            "Iteration 9330 , obj. function = 2.0294573745877336\n",
            "Iteration 9340 , obj. function = 2.0291321846702353\n",
            "Iteration 9350 , obj. function = 2.028809132225466\n",
            "Iteration 9360 , obj. function = 2.0284882032038203\n",
            "Iteration 9370 , obj. function = 2.028169383648004\n",
            "Iteration 9380 , obj. function = 2.027852659692561\n",
            "Iteration 9390 , obj. function = 2.027538017563072\n",
            "Iteration 9400 , obj. function = 2.027225443575716\n",
            "Iteration 9410 , obj. function = 2.026914924136596\n",
            "Iteration 9420 , obj. function = 2.026606445741157\n",
            "Iteration 9430 , obj. function = 2.026299994973647\n",
            "Iteration 9440 , obj. function = 2.0259955585064517\n",
            "Iteration 9450 , obj. function = 2.0256931230995767\n",
            "Iteration 9460 , obj. function = 2.0253926756000786\n",
            "Iteration 9470 , obj. function = 2.0250942029414403\n",
            "Iteration 9480 , obj. function = 2.0247976921430224\n",
            "Iteration 9490 , obj. function = 2.0245031303095127\n",
            "Iteration 9500 , obj. function = 2.0242105046303953\n",
            "Iteration 9510 , obj. function = 2.023919802379318\n",
            "Iteration 9520 , obj. function = 2.0236310109136006\n",
            "Iteration 9530 , obj. function = 2.0233441176736386\n",
            "Iteration 9540 , obj. function = 2.023059110182402\n",
            "Iteration 9550 , obj. function = 2.0227759760448945\n",
            "Iteration 9560 , obj. function = 2.022494702947521\n",
            "Iteration 9570 , obj. function = 2.0222152786577023\n",
            "Iteration 9580 , obj. function = 2.0219376910232025\n",
            "Iteration 9590 , obj. function = 2.021661927971717\n",
            "Iteration 9600 , obj. function = 2.0213879775102424\n",
            "Iteration 9610 , obj. function = 2.021115827724666\n",
            "Iteration 9620 , obj. function = 2.0208454667791025\n",
            "Iteration 9630 , obj. function = 2.020576882915524\n",
            "Iteration 9640 , obj. function = 2.020310064453181\n",
            "Iteration 9650 , obj. function = 2.020044999788089\n",
            "Iteration 9660 , obj. function = 2.0197816773925528\n",
            "Iteration 9670 , obj. function = 2.0195200858146234\n",
            "Iteration 9680 , obj. function = 2.019260213677657\n",
            "Iteration 9690 , obj. function = 2.0190020496797487\n",
            "Iteration 9700 , obj. function = 2.0187455825933225\n",
            "Iteration 9710 , obj. function = 2.0184908012645737\n",
            "Iteration 9720 , obj. function = 2.01823769461302\n",
            "Iteration 9730 , obj. function = 2.017986251631011\n",
            "Iteration 9740 , obj. function = 2.0177364613832607\n",
            "Iteration 9750 , obj. function = 2.0174883130063392\n",
            "Iteration 9760 , obj. function = 2.017241795708235\n",
            "Iteration 9770 , obj. function = 2.016996898767872\n",
            "Iteration 9780 , obj. function = 2.016753611534638\n",
            "Iteration 9790 , obj. function = 2.016511923427932\n",
            "Iteration 9800 , obj. function = 2.016271823936692\n",
            "Iteration 9810 , obj. function = 2.0160333026189643\n",
            "Iteration 9820 , obj. function = 2.0157963491014192\n",
            "Iteration 9830 , obj. function = 2.015560953078902\n",
            "Iteration 9840 , obj. function = 2.015327104313993\n",
            "Iteration 9850 , obj. function = 2.0150947926365763\n",
            "Iteration 9860 , obj. function = 2.0148640079433875\n",
            "Iteration 9870 , obj. function = 2.014634740197544\n",
            "Iteration 9880 , obj. function = 2.0144069794281703\n",
            "Iteration 9890 , obj. function = 2.0141807157299123\n",
            "Iteration 9900 , obj. function = 2.013955939262524\n",
            "Iteration 9910 , obj. function = 2.0137326402504203\n",
            "Iteration 9920 , obj. function = 2.0135108089823195\n",
            "Iteration 9930 , obj. function = 2.0132904358107226\n",
            "Iteration 9940 , obj. function = 2.013071511151574\n",
            "Iteration 9950 , obj. function = 2.0128540254837963\n",
            "Iteration 9960 , obj. function = 2.0126379693489103\n",
            "Iteration 9970 , obj. function = 2.0124233333505996\n",
            "Iteration 9980 , obj. function = 2.0122101081542962\n",
            "Iteration 9990 , obj. function = 2.011998284486808\n",
            "Iteration 10000 , obj. function = 2.0117878531358886\n",
            "Iteration 10010 , obj. function = 2.011578804949855\n",
            "Iteration 10020 , obj. function = 2.011371130837146\n",
            "Iteration 10030 , obj. function = 2.011164821765999\n",
            "Iteration 10040 , obj. function = 2.010959868763988\n",
            "Iteration 10050 , obj. function = 2.0107562629176767\n",
            "Iteration 10060 , obj. function = 2.010553995372216\n",
            "Iteration 10070 , obj. function = 2.010353057330945\n",
            "Iteration 10080 , obj. function = 2.0101534400550505\n",
            "Iteration 10090 , obj. function = 2.009955134863127\n",
            "Iteration 10100 , obj. function = 2.0097581331308683\n",
            "Iteration 10110 , obj. function = 2.009562426290622\n",
            "Iteration 10120 , obj. function = 2.009368005831076\n",
            "Iteration 10130 , obj. function = 2.009174863296855\n",
            "Iteration 10140 , obj. function = 2.008982990288133\n",
            "Iteration 10150 , obj. function = 2.0087923784603485\n",
            "Iteration 10160 , obj. function = 2.0086030195237483\n",
            "Iteration 10170 , obj. function = 2.0084149052430798\n",
            "Iteration 10180 , obj. function = 2.008228027437232\n",
            "Iteration 10190 , obj. function = 2.0080423779788448\n",
            "Iteration 10200 , obj. function = 2.007857948794016\n",
            "Iteration 10210 , obj. function = 2.0076747318618553\n",
            "Iteration 10220 , obj. function = 2.007492719214256\n",
            "Iteration 10230 , obj. function = 2.0073119029354567\n",
            "Iteration 10240 , obj. function = 2.007132275161705\n",
            "Iteration 10250 , obj. function = 2.006953828080983\n",
            "Iteration 10260 , obj. function = 2.00677655393258\n",
            "Iteration 10270 , obj. function = 2.006600445006838\n",
            "Iteration 10280 , obj. function = 2.006425493644728\n",
            "Iteration 10290 , obj. function = 2.0062516922375964\n",
            "Iteration 10300 , obj. function = 2.0060790332267797\n",
            "Iteration 10310 , obj. function = 2.0059075091033245\n",
            "Iteration 10320 , obj. function = 2.0057371124076124\n",
            "Iteration 10330 , obj. function = 2.0055678357290656\n",
            "Iteration 10340 , obj. function = 2.0053996717058067\n",
            "Iteration 10350 , obj. function = 2.0052326130243556\n",
            "Iteration 10360 , obj. function = 2.0050666524193135\n",
            "Iteration 10370 , obj. function = 2.0049017826730013\n",
            "Iteration 10380 , obj. function = 2.0047379966152348\n",
            "Iteration 10390 , obj. function = 2.0045752871229165\n",
            "Iteration 10400 , obj. function = 2.0044136471197915\n",
            "Iteration 10410 , obj. function = 2.0042530695761083\n",
            "Iteration 10420 , obj. function = 2.0040935475083077\n",
            "Iteration 10430 , obj. function = 2.003935073978762\n",
            "Iteration 10440 , obj. function = 2.003777642095442\n",
            "Iteration 10450 , obj. function = 2.0036212450115864\n",
            "Iteration 10460 , obj. function = 2.0034658759254658\n",
            "Iteration 10470 , obj. function = 2.0033115280800677\n",
            "Iteration 10480 , obj. function = 2.0031581947627606\n",
            "Iteration 10490 , obj. function = 2.0030058693050625\n",
            "Iteration 10500 , obj. function = 2.0028545450823207\n",
            "Iteration 10510 , obj. function = 2.0027042155134085\n",
            "Iteration 10520 , obj. function = 2.002554874060467\n",
            "Iteration 10530 , obj. function = 2.002406514228621\n",
            "Iteration 10540 , obj. function = 2.0022591295656733\n",
            "Iteration 10550 , obj. function = 2.002112713661842\n",
            "Iteration 10560 , obj. function = 2.001967260149462\n",
            "Iteration 10570 , obj. function = 2.001822762702749\n",
            "Iteration 10580 , obj. function = 2.001679215037482\n",
            "Iteration 10590 , obj. function = 2.0015366109107626\n",
            "Iteration 10600 , obj. function = 2.001394944120696\n",
            "Iteration 10610 , obj. function = 2.0012542085061735\n",
            "Iteration 10620 , obj. function = 2.001114397946573\n",
            "Iteration 10630 , obj. function = 2.000975506361537\n",
            "Iteration 10640 , obj. function = 2.0008375277106136\n",
            "Iteration 10650 , obj. function = 2.0007004559931163\n",
            "Iteration 10660 , obj. function = 2.0005642852477545\n",
            "Iteration 10670 , obj. function = 2.0004290095524455\n",
            "Iteration 10680 , obj. function = 2.000294623024038\n",
            "Iteration 10690 , obj. function = 2.0001611198180242\n",
            "Iteration 10700 , obj. function = 2.0000284941283395\n",
            "Iteration 10710 , obj. function = 1.9998967401870478\n",
            "Iteration 10720 , obj. function = 1.9997658522641846\n",
            "Iteration 10730 , obj. function = 1.9996358246673915\n",
            "Iteration 10740 , obj. function = 1.9995066517417415\n",
            "Iteration 10750 , obj. function = 1.9993783278694963\n",
            "Iteration 10760 , obj. function = 1.9992508474698225\n",
            "Iteration 10770 , obj. function = 1.9991242049985738\n",
            "Iteration 10780 , obj. function = 1.9989983949480523\n",
            "Iteration 10790 , obj. function = 1.9988734118467477\n",
            "Iteration 10800 , obj. function = 1.9987492502591522\n",
            "Iteration 10810 , obj. function = 1.9986259047854327\n",
            "Iteration 10820 , obj. function = 1.9985033700612849\n",
            "Iteration 10830 , obj. function = 1.9983816407576458\n",
            "Iteration 10840 , obj. function = 1.9982607115804847\n",
            "Iteration 10850 , obj. function = 1.998140577270588\n",
            "Iteration 10860 , obj. function = 1.9980212326032842\n",
            "Iteration 10870 , obj. function = 1.9979026723882505\n",
            "Iteration 10880 , obj. function = 1.997784891469297\n",
            "Iteration 10890 , obj. function = 1.9976678847240914\n",
            "Iteration 10900 , obj. function = 1.997551647064013\n",
            "Iteration 10910 , obj. function = 1.9974361734338575\n",
            "Iteration 10920 , obj. function = 1.9973214588116541\n",
            "Iteration 10930 , obj. function = 1.9972074982084473\n",
            "Iteration 10940 , obj. function = 1.997094286668073\n",
            "Iteration 10950 , obj. function = 1.9969818192669468\n",
            "Iteration 10960 , obj. function = 1.9968700911138242\n",
            "Iteration 10970 , obj. function = 1.9967590973496594\n",
            "Iteration 10980 , obj. function = 1.9966488331472851\n",
            "Iteration 10990 , obj. function = 1.996539293711318\n",
            "Iteration 11000 , obj. function = 1.9964304742778456\n",
            "Iteration 11010 , obj. function = 1.996322370114311\n",
            "Iteration 11020 , obj. function = 1.9962149765192472\n",
            "Iteration 11030 , obj. function = 1.9961082888220778\n",
            "Iteration 11040 , obj. function = 1.9960023023829452\n",
            "Iteration 11050 , obj. function = 1.99589701259248\n",
            "Iteration 11060 , obj. function = 1.9957924148716046\n",
            "Iteration 11070 , obj. function = 1.995688504671353\n",
            "Iteration 11080 , obj. function = 1.9955852774726603\n",
            "Iteration 11090 , obj. function = 1.9954827287861479\n",
            "Iteration 11100 , obj. function = 1.9953808541519613\n",
            "Iteration 11110 , obj. function = 1.9952796491395532\n",
            "Iteration 11120 , obj. function = 1.9951791093475\n",
            "Iteration 11130 , obj. function = 1.9950792304033187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f005b4d4fd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VOX5//H3DSiIoFihFiUSFxQX\nFDC4+61xrSBgqyJq3dCiiFVBxRUXtCq41oL7UhA3XKu4UCxR26qYgKxu4AYq/kS0VmpdkPv3x3NS\nQswyE2Zyzpx8Xtc1V2bOnMzcORd8cnKfZ57H3B0REUmXZnEXICIiuadwFxFJIYW7iEgKKdxFRFJI\n4S4ikkIKdxGRFFK4i4ikkMJdRCSFFO4iIinUIq43bt++vRcXF8f19iIiBWnGjBmfu3uH+vaLLdyL\ni4upqKiI6+1FRAqSmX2YyX5qy4iIpJDCXUQkhRTuIiIppHAXEUkhhbuISAop3LMxZgyUla2+raws\nbBcRSRCFezZ69YIBA1YFfFlZeNyrV7x1iYhUE9s494JUWgqTJoVAHzIEbrklPC4tjbsyEZHV6Mw9\nW6WlIdgvvzx8VbCLSAIp3LNVVhbO2EeODF+r9+BFRBJA4Z6Nyh77pEkwatSqFo0CXkQSRuGejfLy\n1XvslT348vJ46xIRqcbcPZY3LikpcU0cJiKSHTOb4e4l9e2nM3cRkRRSuIuIpJDCXUQkhRTuIiIp\npHAXEUkhhbuISAop3EVEUkjhLiKSQgp3EZEUyijczewDM5trZrPM7CcfK7XgJjNbaGZzzKxn7ksV\nEZFMZTOfe6m7f17LcwcBXaLbLsAt0VcREYlBrtoy/YEJHrwKtDOzjjl6bRERyVKm4e7AX81shpkN\nruH5TYDFVR5/FG1bjZkNNrMKM6tYunRp9tWKiEhGMg33Pd29J6H9MtTM/q8hb+but7t7ibuXdOjQ\noSEvISIiGcgo3N394+jrZ8DjwM7VdvkYKKryuFO0TUREYlBvuJvZumbWtvI+cAAwr9puTwLHRqNm\ndgW+cvclOa9WREQykslomY2Ax82scv/73f05MzsFwN1vBZ4BegMLgW+AE/JTroiIZKLecHf394Ad\na9h+a5X7DgzNbWkiItJQ+oSqiEgKKdxFRFJI4S4ikkIKdxGRFFK4i4ikkMJdRCSFFO4iIimkcBcR\nSSGFu4hICincRURSSOEuIpJCCncRkRRSuIuIpJDCXUQkhRTuIiIppHAXEUkhhbuISAop3EVEUkjh\nLiKSQgp3EZEUUriLiKSQwl1EJIUU7iIiKaRwFxFJIYW7iEgKKdxFRFJI4S4ikkIKdxGRFFK4i4ik\nUMbhbmbNzex1M5tcw3PHm9lSM5sV3U7KbZkiIpKNFlnsewbwJrBeLc8/5O6nrXlJIiKypjI6czez\nTkAf4M78liMiIrmQaVvmRmAEsLKOfQ41szlm9oiZFdW0g5kNNrMKM6tYunRptrU2zJgxUFa2+ray\nsrC9IfuJiBSAesPdzA4GPnP3GXXs9hRQ7O47AFOB8TXt5O63u3uJu5d06NChQQVnrVcvGDBgVXCX\nlYXHvXo1bD8RkQJg7l73DmZXAccAK4BWhJ77Y+7+21r2bw584e7r1/W6JSUlXlFR0aCis1YZ1EOG\nwC23wKRJUFra8P1ERGJiZjPcvaS+/eo9c3f38929k7sXAwOBadWD3cw6VnnYj3DhNTlKS0NgX355\n+FpbYGe6n4hIwjV4nLuZjTKzftHD081svpnNBk4Hjs9FcTlTVhbOxEeODF+r99az3U9EJOHqbcvk\nS6O1ZSpbLZUtluqPs91PRCRGOWvLJM1//wvTpkHGv5PKy1cP6NLS8Li8vGH7iYgUgII7c7/nHhg0\nCHbcEYYPh4EDYe2181CgiEgCpfbM/cgj4c474Ycf4LjjoLgYrrwSli2LuzIRkeQouHBv1QpOPBHm\nzYMpU2CHHeDCC6GoKAxwefvtuCsUEYlfwYV7JTM44AB47jmYOxeOOiq0bLp2hb59w/XQmDpOIiKx\nK9hwr2r77UOr5sMP4ZJLYPp02Gcf6NkT7r0Xvv8+7gpFRBpXKsK90kYbwaWXhpC/444Q6sceG/ry\nV10FX3wRd4UiIo0jVeFeaZ114KSTQl/+ueegWze44ALo1AlOPRXeeSfuCkVE8iuV4V7JDA48MFx4\nnTMnjLS5667Ql+/XD154QX15EUmnVId7Vd26hWBftCjMLvDKK+FzSjvtBBMnqi8vIunSZMK90kYb\nwWWXhZC//Xb49ls45hjYbDP15UUkPZpcuFdaZx343e9CX/7ZZ2G77UJfvqgIhg6FBQvirlBEpOGa\nbLhXatYMfvUr+OtfQ1/+iCPCsMqtt4b+/eHFF9WXF5HC0+TDvapu3eDuu8NQyosugpdfhr33hpIS\nuO8+9eVFpHAo3Gvwi1/AqFGr+vLffAO//S1svjlcfbX68iKSfAr3OlT25efPh2eegW22gfPPD335\n005TX15EkkvhnoFmzeCgg2DqVJg9O6zhcccdoS9/yCHw0kvqy4tIsijcs7TDDmGCssq+/D/+Ab/8\n5aq+/A8/xF2hiIjCvcGq9uVvu21VX36zzaCs9xi+frLa+qtlZTBmTDzFikiTo3BfQ61bw+DBoS//\n9NNhaoNRz/bi2/4DuOnXZSxcyKr1WHv1irtcEWkiFO450qwZ9O4Nzz8PN84q5e4DJ3HkEwN4oMvF\nfPWrAcy+cBK+txbaFpHGoXDPgx13hHOfK6XVmUMYyeXc0XwI3YeV0qsX3H+/+vIikn8K93wpK6Pt\nxFtg5EjOWvcWnhxWxvLlcPTRoS8/Zgx8+WXcRYpIWinc86Gyxz5pEowahU2aRN97B/DGuDImTw5D\nKM89N4yXP/10ePfduAsWkbRRuOdDeXkI9tKox15aCpMm0WxGOX36wN/+BrNmwWGHwa23Qpcu8Otf\nw9//rvHyIpIb5jGlSUlJiVdUVMTy3kmyZAmMGwe33BKmNSgpgeHDQ/CvtVbc1YlI0pjZDHcvqW8/\nnbnHrGNHuOIKWLw4BPy//w1HHRXmsbnmGvjXv+KuUEQKkcI9IVq3hlNOgTffhKeegq22ghEjwrqv\nZ5yhvryIZEfhnjDNmsHBB4e+/Ouvw6GHhjP6Ll3gN78J0x2oLy8i9ck43M2suZm9bmaTa3iupZk9\nZGYLzWy6mRXnssimqnt3GD8ePvggzEb54ouw116wyy7w4IMaLy8itcvmzP0M4M1anjsR+NLdtwRu\nAEavaWGyysYbwx/+EOaxufnm0Ic/8kjYYgu49lr15UXkpzIKdzPrBPQB7qxll/7A+Oj+I8C+ZmZr\nXp5Ute66MGQIvPUWPPkkbLklnHNOGC9/xhnw3ntxVygiSZHpmfuNwAhgZS3PbwIsBnD3FcBXwIZr\nXJ3UqFkz6NsXpk2DmTPDGPmbbw59+UMPhX/+U315kaau3nA3s4OBz9x9xpq+mZkNNrMKM6tYunTp\nmr6cAD16wIQJoS9/7rnhw7F77gm77goPPQQrVsRdoYjEIZMz9z2Afmb2AfAgsI+ZTay2z8dAEYCZ\ntQDWB5ZVfyF3v93dS9y9pEOHDmtUuKxuk03gyivDePmbbw7z1gwcGPry110HX30Vd4Ui0pjqDXd3\nP9/dO7l7MTAQmObuv62225PAcdH9w6J91BiIQfW+/Oabw9lnh/HyZ54J778fd4Ui0hgaPM7dzEaZ\nWb/o4V3Ahma2EBgOnJeL4qThKvvyZWUwY0ZY63XcuHAR9rDD4OWX1ZcXSTPNLROXMWPCykylVRbw\nKCsLk46NGJGXt/z4Yxg7NiwL+OWXYbz88OHhw1EtWuTlLUUkxzS3TNL16hWmBS6L1lpthKX4NtkE\nrroq9OXHjYNly+CII0Jf/vrr1ZcXSROFe1yiaYAZMAAuvnjV/O+l+V+Kb9114dRTQ1/+L38Ji4ec\ndVYYLz9smPryImmgcI9TaWm4+nn55eFrIwR7Vc2bQ79+8MILUFER7o8dG/ryhx8Or7zSqOWISA4p\n3ONUVhZmBRs5MnytbNHEYKedYOLEcNZ+zjlhoe/dd4fddoOHH9Z4eZFCo3CPS7Wl+P7Xookx4CEM\nmbz66tCXHzsWli4NZW25pfryIoVE4R6XWpbio7w8P+83ZsxPf3GUlYXtNWjTBoYOhbffhieegM6d\nV/Xlhw8Pn4gVkeTSUMimoupfCqWlP32cgYoKuOGG8C0rV4Z5bIYNC60bEWkcGgopq8vB6JySErjv\nvjD75Nlnw9Sp6suLJJXCvSnJ0eicoiIYPTr05f/0p9X78jfcENaBFZF4KdybkhyPzmnTBk47LfTl\nH38cNt009OM7dQr9+Q8/zFHdIpI1hXtTkcfROc2bh7lrXnoJXnstrAH7xz+GScuOOAJefTUH9YtI\nVhTuTUUjjc7p1Qvuvz+Mlz/7bJgyJfTkd98dHnlEfXmRxqLRMpJXy5fDPffAjTeGC7HFxWFJwEGD\nYL314q5OpPBotIwkQps28PvfwzvvwGOPhX78sGHhouzZZ6svL5IvCndpFM2bh7Ve//730Jfv0yec\nzW+xRejLT58ed4Ui6aJwl0ZXtS8/fHjoy++6K+yxBzz6KPz4Y9wVihQ+hbvEpqgozH6weHEYXbNk\nSVglqkuX8Pjrr+OuUKRwKdwldm3bwumnw4IFoS+/ySZhvddOncIMlYsWZfAiWc6dI5J2CndJjKp9\n+enToXfv8InXzTeHgQNDr75WMaxsJZJkCndJpJ13hgceCMMnhw2DZ58Na77uuWc4u/9JXz7Gla1E\nkkjhLqsksLWx6aZwzTXw0UdhdM0nn4TZKLt0gZtuqtaXj3llK5EkUbjLKglubbRtGz78tGBBGFGz\n8cbhcVFRlb58gla2Eomdu8dy22mnnVwSaNo09/bt3UeODF+nTYu7olq9+qr7EUe4N2/uvm+zaf5V\ny/b+5s1RvZU/R4LrF2kIoMIzyFiducvqMmltJKR9s8su8OCD8O67cOYe5RzVfBLbnFrKXnvB4/8q\n5ccH8riylUjCKdzTIJdhm0lrI2Htm86d4eCXRnD/klJuuCH053/zG9jq5FL+tM4Ili+PpSyReGVy\nep+Pm9oyOVS9BdHQlkQ2r5Pg9s0PP7g/8oj77ru7g/v667ufc477okVxVyay5siwLaNwT4tchO3o\n0T/9vmnTwvaajBwZ/gmNHJn9ezWSV15xHzDAvVmz0Js/8kj38vK4qxJpOIV7U9SYYVvfL5Nsf1Hk\n2fvvuw8f7t62bThEe+3l/vjj7itWxFKOSIMp3JuaxmyTZNK+yVWrKMe++sr9+uvdO3cO//q32ML9\nppvcv/461rJEMpazcAdaAa8Bs4H5wGU17HM8sBSYFd1Oqu91Fe451NhBmulZecL78g8/7L7bbuF/\nQbt27iNGuC9eHHdlInXLZbgb0Ca6vxYwHdjVfxruYzN5w8qbwj2HEtYCWU0B9OVfftn98MNDX75F\nC/ejjlJfXpIr03Cvdyhk9HqVg8nWim7xrM0nNRsx4qfj0UtLw/Y4FcgnRnfbLUxD8+67YdWop54K\nozp/+Uv4y180v7wUpozGuZtZczObBXwGTHX3mtbNOdTM5pjZI2ZWlNMqpfBUjn2fNAlGjVo1qVdC\nAx7C+q7XXx/GyV9/fVgC8JBDoGtXGDsWjZeXgpJRuLv7j+7eHegE7Gxm21fb5Smg2N13AKYC42t6\nHTMbbGYVZlaxdOnSNalbkq68fPVZGStnbSyAT4yut16YiXLhwlDyhhuGM/qiIjjvvBD+IklnoYWT\nxTeYXQx84+7X1vJ8c+ALd1+/rtcpKSnxioqKrN5bJC6vvBLO5h97DJo1C+u+DhsGO+0Ud2XS1JjZ\nDHcvqW+/es/czayDmbWL7q8D7A+8VW2fjlUe9gPezK5ckQSpYTqH3b4t4+FeY1i4MJzFP/kklJTA\n3nuH+ytXxlOqSG0yact0BMrMbA5QTui5TzazUWbWL9rndDObb2azgdMJo2dEClMdc+dstlk4g1+8\nGK67Lizy3b8/bL01jBsH//lPvKWLVMq6LZMrastIolUG+pAhYaRPLas6rVgRWjXXXReWAdxgAzj5\nZDjttLAWrEiu5awtI5Iqmc6gmeGqTi1ahN8Br74K//wn7LNPeKniYjjmGJg5Mz8/hkh9FO7StGQ6\nXXGWY/TNYPfd4ZFHwiib006DJ54IF1zVl5dYZPJJp3zc9AlViU190yLkaDqHf/3L/dpr3YuKwod0\nu3RxHzfOffnyHP0c0iShlZhEalFfyyVHY/TXXx/OOgveey+sGNWuHQwdGsbLX3ABfPxxjn4ekRro\ngqo0PRleLM01d3j55TDa5oknwnj5gQNh+HDo0SPvby8poQuqIjWJcVoEM9hjD3j0UViwIJzFP/EE\nPNBzDMO6l/HUU1X68jGsSSvponCXpiUh0yJsvjnceGMYL7/Tyb24aO4Aru9XRteu8Jczy/DD41uT\nVtJBbRmRBFgxtYwVhw5gYtsh9P/kFk5qO4ntf1/K0KGw8cZxVydJoraMSAFpsX8prc4cwkmfXM63\nxw+hxf6lXHVVGC9/7LEwa1bcFUqhUbiLJEGVcfVFk2/h0dPKWLAgXPN97LFwwXWffWDyZI2Xl8wo\n3EXiVstF3i0WlfHHP4YphseMCRdh+/aFbbaBW2+Fb76Ju3BJMoW7SNzqucjbrh2cc04YL3///WG+\n+SFDwnj5Cy+ETz6JsXZJLF1QFSkw7mEem8rx8i1awJFHhvnlu3ePuzrJN11QFUkpM9hzz9CLX7AA\nTjkljJ3v0QP23Reeflp9eVG4izRMprNL5tkWW8BNN4Xx8mPGwDvvwMEHw7bbwm23qS/flCncRRoi\n09klG8kGG6zel2/TJpzRb7opXHQRLFkSS1kSI4W7SENUXvQcMAAuvnjVaJdGmKOmLmutFfrv5eXw\n0kuw115w5ZXQuTMcfzzMnh1redKIFO4iDZXhgh5xMAvB/vjjoVVz8snw8MPhgut++8Ezz6gvn3YK\nd5GGynJBj7hsuSX86U9hvPzo0fDWW9CnD2y3Hdx+O/z3v3kuICHXJ5oahbtIQzT27JI5CMgNNoAR\nI8Ki3vfdB61bhzP6oqLw++nTT3Ncc6VMr0/ol0BuZbKiRz5uWolJCtro0TWv4DR6dMP2q0+OVoeq\nauVK9xdfdO/f393Mfe213Y8/3n327Aa/ZO3qW/2q6j45/BnTiAxXYlK4i+RTLgMrk4BsoHfecR86\n1L1165AK++3n/swz7j/+mLO3CHVD+FqbPP6MaaFwF0mKXAZWJgFZnzr+mli2zP3qq9033ji8Tdeu\n7rfd5v7NNw1/u/+9fqbHYE1/xlz9tZRQCneRJMlFKOfql0QGf0189537xInuPXuGsivfdsmSaq+V\nSZBm89dLfT9jrt+vACncRZIiF6GcaWBletaaYU0rV7q/8IJ7v36r+vInnOA+Z04WdWVbU12vlelx\nSHF7R+EukgS5OovMZUBWquuviRreb9H4af7YbqP/15fff/+oL/98joI0x7+YcvLXUgIp3EWSII7+\nbzYjU2rbp45fEsuWuV911aq+/DbbuM/o08hBWl9w68xd4S6SSnWFX45aG999537vve6/23Kaf0Z7\nv2adkb68dXtf9kieg3QNfjFlLYEXZxXuIk1VLi5KVsrgDHll+/b++vXTvG9f970JQT/6oGk+d25u\nfpyf1JmrHn+u3q+R5SzcgVbAa8BsYD5wWQ37tAQeAhYC04Hi+l5X4S6SB409rr5akL79tvsN/af5\nBS1GO7gfcID7s8+GC7M5kdQ2VyPKZbgb0Ca6v1YU3rtW2+dU4Nbo/kDgofpeV+EukgcJ+UTs55+7\nX3mle8eOIWW23db9jjtyMF4+l3L5F0wjyktbBmgNzAR2qbZ9CrBbdL8F8DnREn613RTuIgmWo18S\n333nPmGCe/fuIW06dHC/5BL3Tz/NXakNVqDDKnMa7kBzYBawHBhdw/PzgE5VHr8LtK/rNRXuIk3H\nypUhE/v2DanTsqX7oEGen758Nhrz4myOZBruGc0K6e4/unt3oBOws5ltn8n3VWdmg82swswqli5d\n2pCXEJECZBamu3/yyTDl8KBB8MAD0K0bHHggTJkSFv5udPXNyV9evvoiLJWLtJSXN36tWTLP8oia\n2cXAN+5+bZVtU4BL3f0VM2sBfAp08DpevKSkxCsqKhpYtogUumXLwjqvY8eGZQC32w6GDYOjj4ZW\nrRqpiMrph4cMCXPyJ2A1rfqY2Qx3L6lvv3rP3M2sg5m1i+6vA+wPvFVttyeB46L7hwHT6gp2EZEN\nN4QLLoAPPoAJE6BFCzjppLDu62WXwWef5bmAxp6Tv5Fl0pbpCJSZ2RygHJjq7pPNbJSZ9Yv2uQvY\n0MwWAsOB8/JTroikzdprwzHHwOuvw7RpsMsucOmlIeRPOgnmz8/TGxdwyyUTWbdlckVtGRGpzdtv\nw403wvjxYRnAAw+E4cNh//1D/74py1lbRkSksW29dWiBL1oEV1wBs2eHgO/WDe6+G779Nu4Kk0/h\nLiKJ1b49XHhh6MuPHw/Nm8OJJ0Lnzo3Uly9gCncRSbyWLeHYY2HWLPjb38La2pV9+d/9Dt54I+4K\nk0fhLiIFwwz22QcmT4Y334Tjj4eJE8MwyoMOgqlTYxovn0AKdxEpSF27wq23wuLF4TNIs2bBAQfA\nDjvAPfeoL69wF5GC1r49XHRR6Mv/+c/QrFn4BGznzmH4elP9MLzCXURSoWVLOO64cAb//PNQUgKX\nXBL68oMHN72+vMJdRFLFDPbdF55+OgT6scfCvfeGvnzv3iH4m0JfXuEuIqm1zTZh/ppFi0KLZubM\n8EGoHXcMffnvvou7wvxRuItI6nXoACNHwocfhlCHVX35yy9PZ19e4S4iTUbLlmH45OzZYdhkz55w\n8cWhL3/yyWF4ZVoo3EWkyTGD/faDZ54JE5Mdc0z4BOy220KfPuGDUoXel1e4i0iTtu22cPvtYbz8\nqFFQURGCv3v3MLSyUPvyCncREVbvy999N6xcCSecEPryV1wBn38ed4XZUbiLiFTRqlUI9Tlz4K9/\nhR49QugXFcEpp4RlAguBwl1EpAZmYdjks8+u6sv/+c9heOXBB4eFRZLcl1e4i4jUo7Ivv2hRmGq4\nvDx8UKp793AhNol9eYW7iEiGfv7zMHTyww/hrrvgxx/D0MriYvjDH8Ki30mhcBcRyVKrVuFDUHPn\nwpQp4ROvF10U+vJDhoRlAuOmcBcRaSCzMM3wc8/BvHlw9NHhE7Bdu0LfvvH25RXuIiI5sN12cMcd\noS9/6aUwfXroy/foARMmwPffN249CncRkRz6+c/DVMOLFsGdd8IPP4SpiIuL4corG68vr3AXEcmD\nVq3CYt7z5oW2TbduYbHvoiK47rr8v7/CXUQkj8zgwAPDhde5c+Goo8KnXvOtRf7fQkREALbfPrRq\nGoPO3EVEUkjhLiKSQgp3EZEUUriLiKRQveFuZkVmVmZmb5jZfDM7o4Z99jazr8xsVnS7OD/liohI\nJjIZLbMCOMvdZ5pZW2CGmU119zeq7fd3dz849yWKiEi26j1zd/cl7j4zuv818CawSb4LExGRhsuq\n525mxUAPYHoNT+9mZrPN7Fkz2y4HtYmISANl/CEmM2sDPAqc6e7/rvb0TKCzuy83s97AE0CXGl5j\nMDA4erjczBIwMWaN2gMFtmLi/xRq7YVaN6j2uDTV2jP6fKt5BvNRmtlawGRgirtfn8H+HwAl7l6Q\nB97MKty9JO46GqJQay/UukG1x0W11y2T0TIG3AW8WVuwm9kvov0ws52j103QmiQiIk1LJm2ZPYBj\ngLlmNivadgGwKYC73wocBgwxsxXAf4GBnsmfBCIikhf1hru7/wOwevYZC4zNVVEJcHvcBayBQq29\nUOsG1R4X1V6HjHruIiJSWDT9gIhICjWJcDezu83sMzObV2Xbjmb2ipnNNbOnzGy9Ks+db2YLzext\nMzuwyvZfRdsWmtl5SavdzPY3sxnR9hlmtk+V79kp2r7QzG6qvACelNqrPL+pmS03s7OrbEv0cY+e\n2yF6bn70fKtoe6KPu5mtZWbjo+1vmtn5Vb6nUY97bVOdmNnPzGyqmS2Ivm4QbbfomC40szlm1rPK\nax0X7b/AzI5LYO1HRzXPNbOXzWzHKq+Vm+Pu7qm/Af8H9ATmVdlWDvwyuj8IuDy6vy0wG2gJbAa8\nCzSPbu8CmwNrR/tsm7DaewAbR/e3Bz6u8j2vAbsSrp88CxyUpNqrPP8I8DBwdvS4EI57C2AOsGP0\neEOgeSEcd+Ao4MHofmvgA6A4juMOdAR6RvfbAu9E/x/HAOdF288DRkf3e0fH1KJjPD3a/jPgvejr\nBtH9DRJW++6VNQEHVak9Z8e9SZy5u/tLwBfVNm8FvBTdnwocGt3vT/jH/p27vw8sBHaObgvd/T13\n/x54MNo3MbW7++vu/km0fT6wjpm1NLOOwHru/qqHf0ETgEOSVDuAmR0CvB/VXinxxx04AJjj7rOj\n713m7j8WyHF3YF0zawGsA3wP/JsYjrvXPtVJf2B8tNt4Vh3D/sAED14F2kXH/EBgqrt/4e5fRj/v\nr5JUu7u/HNUG8CrQKbqfs+PeJMK9FvNZddAOB4qi+5sAi6vs91G0rbbtcait9qoOBWa6+3eEOj+q\n8lziarfwCehzgcuq7V8Ix30rwM1sipnNNLMR0fbEH3fCX0r/AZYAi4Br3f0LYj7utvpUJxu5+5Lo\nqU+BjaL7ify/mmHtVZ1I+AsEclh7Uw73QcCpZjaD8GfU9zHXk406a7cwt89o4OQYaqtPbbVfCtzg\n7svjKiwDtdXeAtgTODr6+msz2zeeEmtVW+07Az8CGxPakGeZ2ebxlBhYHVOdRH8BJXaIX7a1m1kp\nIdzPzXUtTXaBbHd/i/DnNGa2FdAneupjVj8T7hRto47tjaqO2jGzTsDjwLHu/m60+WNW/dkHyax9\nF+AwMxsDtANWmtm3wAySf9w/Al7yaLoNM3uG0POeSPKP+1HAc+7+A/CZmf0TKCGcPTb6cbcw1cmj\nwH3u/li0+f+ZWUd3XxK1XT6Lttf2f/VjYO9q21/IZ92Qde2Y2Q7AnYTrMJWf6K8rf7KTz4sMSboR\nLhJVvcD08+hrM0IvdFD0eDt8rGd8AAABUUlEQVRWv6D6HuEiR4vo/masutCxXcJqbxfV9ZsaXqP6\nhb3eSaq92vdcyqoLqoVw3DcgTJ7XOqr3eaBPIRx3whnjPdH9dYE3gB3iOO7RMZoA3Fht+zWsflFy\nTHS/D6tfUH0t2v4zwrWbDaLb+8DPElb7poTrebtX2z9nxz3v/8iScAMeIPQUfyCcZZ0InEG4ov0O\ncDXRB7qi/S8kXLF+myqjGwhX59+JnrswabUDFxH6p7Oq3Cr/U5cA86Lax1b9eZNQe7Xvu5Qo3Avh\nuEf7/5bQ155X+R+4EI470IYwOmk+IdjPieu4E1paThh5VPnvtzdh9NHfgAWEX5w/i/Y3YFxU31zC\nZIWVrzWIEJ4LgRMSWPudwJdV9q3I9XHXJ1RFRFKoKV9QFRFJLYW7iEgKKdxFRFJI4S4ikkIKdxGR\nFFK4i4ikkMJdRCSFFO4iIin0/wGRJuTmUpu1dQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTIhzUEEQEc",
        "colab_type": "text"
      },
      "source": [
        "#### Question 3 Answer Here\n",
        "\n",
        "Approximately 11000 iterations are required to obtain a solution with the level of error with which we are comfortable. It takes so many iterations due to the fact that the 'steps' taken at each parameter update are small, and also it has to be taken into consideration that it's not a direct/steepest route to the minimum of the objective function, as at any one time we are keeping one parameter fixed, whilst updating the other one, resulting in characteristic 'steps', rather than a smooth curve towards the minimum as seen with GD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqmmThhvEQEd",
        "colab_type": "text"
      },
      "source": [
        "## Multiple Input Solution with Linear Algebra\n",
        "\n",
        "You've now seen how slow it can be to perform a coordinate ascent on a system. Another approach to solving the system (which is not always possible, particularly in *non-linear* systems) is to go direct to the minimum. To do this we need to introduce *linear algebra*. We will represent all our errors and functions in the form of linear algebra. \n",
        "\n",
        "As we mentioned above, linear algebra is just a shorthand for performing lots of multiplications and additions simultaneously. What does it have to do with our system then? Well the first thing to note is that the linear function we were trying to fit has the following form:\n",
        "$$\n",
        "f(x) = mx + c\n",
        "$$\n",
        "the classical form for a straight line. From a linear algebraic perspective we are looking for multiplications and additions. We are also looking to separate our parameters from our data. The data is the *givens* remember, in French the word is donn√©es literally translated means *givens* that's great, because we don't need to change the data, what we need to change are the parameters (or variables) of the model. In this function the data comes in through $x$, and the parameters are $m$ and $c$. \n",
        "\n",
        "What we'd like to create is a vector of parameters and a vector of data. Then we could represent the system with vectors that represent the data, and vectors that represent the parameters. \n",
        "\n",
        "We look to turn the multiplications and additions into a linear algebraic form, we have one multiplication ($m\\times c$) and one addition ($mx + c$). But we can turn this into a inner product by writing it in the following way,\n",
        "$$\n",
        "f(x) = m \\times x + c \\times 1,\n",
        "$$\n",
        "in other words we've extracted the unit value, from the offset, $c$. We can think of this unit value like an extra item of data, because it is always given to us, and it is always set to 1 (unlike regular data, which is likely to vary!). We can therefore write each input data location, $\\mathbf{x}$, as a vector\n",
        "$$\n",
        "\\mathbf{x} = \\begin{bmatrix} 1\\\\ x\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "Now we choose to also turn our parameters into a vector. The parameter vector will be defined to contain \n",
        "$$\n",
        "\\mathbf{w} = \\begin{bmatrix} c \\\\ m\\end{bmatrix}\n",
        "$$\n",
        "because if we now take the inner product between these to vectors we recover\n",
        "$$\n",
        "\\mathbf{x}\\cdot\\mathbf{w} = 1 \\times c + x \\times m = mx + c\n",
        "$$\n",
        "In `numpy` we can define this vector as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ulo7dR6GEQEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the vector w\n",
        "w = np.zeros(shape=(2, 1))\n",
        "w[0] = m\n",
        "w[1] = c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u5DvQ6YEQEi",
        "colab_type": "text"
      },
      "source": [
        "This gives us the equivalence between original operation and an operation in vector space. Whilst the notation here isn't a lot shorter, the beauty is that we will be able to add as many features as we like and still keep the same representation. In general, we are now moving to a system where each of our predictions is given by an inner product. When we want to represent a linear product in linear algebra, we tend to do it with the transpose operation, so since we have $\\mathbf{a}\\cdot\\mathbf{b} = \\mathbf{a}^\\top\\mathbf{b}$ we can write\n",
        "$$\n",
        "f(\\mathbf{x}_i) = \\mathbf{x}_i^\\top\\mathbf{w}.\n",
        "$$\n",
        "Where we've assumed that each data point, $\\mathbf{x}_i$, is now written by appending a 1 onto the original vector\n",
        "$$\n",
        "\\mathbf{x}_i = \n",
        "\\begin{bmatrix} \n",
        "1 \\\\\n",
        "x_i\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "## Design Matrix\n",
        "\n",
        "We can do this for the entire data set to form a [*design matrix*](http://en.wikipedia.org/wiki/Design_matrix) $\\mathbf{X}$,\n",
        "\n",
        "$$\\mathbf{X} = \\begin{bmatrix} \n",
        "\\mathbf{x}_1^\\top \\\\\\ \n",
        "\\mathbf{x}_2^\\top \\\\\\ \n",
        "\\vdots \\\\\\\n",
        "\\mathbf{x}_n^\\top\n",
        "\\end{bmatrix} = \\begin{bmatrix}\n",
        "1 & x_1 \\\\\\\n",
        "1 & x_2 \\\\\\\n",
        "\\vdots & \\vdots \\\\\\\n",
        "1 & x_n \n",
        "\\end{bmatrix},$$\n",
        "\n",
        "which in `numpy` can be done with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2FxJojmEQEi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "41852440-9706-4606-c038-cdce0ed6f7a4"
      },
      "source": [
        "X = np.hstack((np.ones_like(x), x))\n",
        "print(X)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.000e+00 1.896e+03]\n",
            " [1.000e+00 1.900e+03]\n",
            " [1.000e+00 1.904e+03]\n",
            " [1.000e+00 1.908e+03]\n",
            " [1.000e+00 1.912e+03]\n",
            " [1.000e+00 1.920e+03]\n",
            " [1.000e+00 1.924e+03]\n",
            " [1.000e+00 1.928e+03]\n",
            " [1.000e+00 1.932e+03]\n",
            " [1.000e+00 1.936e+03]\n",
            " [1.000e+00 1.948e+03]\n",
            " [1.000e+00 1.952e+03]\n",
            " [1.000e+00 1.956e+03]\n",
            " [1.000e+00 1.960e+03]\n",
            " [1.000e+00 1.964e+03]\n",
            " [1.000e+00 1.968e+03]\n",
            " [1.000e+00 1.972e+03]\n",
            " [1.000e+00 1.976e+03]\n",
            " [1.000e+00 1.980e+03]\n",
            " [1.000e+00 1.984e+03]\n",
            " [1.000e+00 1.988e+03]\n",
            " [1.000e+00 1.992e+03]\n",
            " [1.000e+00 1.996e+03]\n",
            " [1.000e+00 2.000e+03]\n",
            " [1.000e+00 2.004e+03]\n",
            " [1.000e+00 2.008e+03]\n",
            " [1.000e+00 2.012e+03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trRvwN40EQEl",
        "colab_type": "text"
      },
      "source": [
        "### Writing the Objective with Linear Algebra\n",
        "\n",
        "When we think of the objective function, we can think of it as the errors where the error is defined in a similar way to what it was in Legendre's day $y_i - f(\\mathbf{x}_i)$, in statistics these errors are also sometimes called [*residuals*](http://en.wikipedia.org/wiki/Errors_and_residuals_in_statistics). So we can think as the objective and the prediction function as two separate parts, first we have,\n",
        "$$\n",
        "E(\\mathbf{w}) = \\sum_{i=1}^n (y_i - f(\\mathbf{x}_i; \\mathbf{w}))^2,\n",
        "$$\n",
        "where we've made the function $f(\\cdot)$'s dependence on the parameters $\\mathbf{w}$ explicit in this equation. Then we have the definition of the function itself,\n",
        "$$\n",
        "f(\\mathbf{x}_i; \\mathbf{w}) = \\mathbf{x}_i^\\top \\mathbf{w}.\n",
        "$$\n",
        "Let's look again at these two equations and see if we can identify any inner products. The first equation is a sum of squares, which is promising. Any sum of squares can be represented by an inner product,\n",
        "$$\n",
        "a = \\sum_{i=1}^{k} b^2_i = \\mathbf{b}^\\top\\mathbf{b},\n",
        "$$\n",
        "so if we wish to represent $E(\\mathbf{w})$ in this way, all we need to do is convert the sum operator to an inner product. We can get a vector from that sum operator by placing both $y_i$ and $f(\\mathbf{x}_i; \\mathbf{w})$ into vectors, which we do by defining \n",
        "$$\n",
        "\\mathbf{y} = \\begin{bmatrix}y_1\\\\y_2\\\\ \\vdots \\\\ y_n\\end{bmatrix}\n",
        "$$\n",
        "and defining\n",
        "$$\n",
        "\\mathbf{f}(\\mathbf{X}; \\mathbf{w}) = \\begin{bmatrix}f(\\mathbf{x}_1; \\mathbf{w})\\\\f(\\mathbf{x}_2; \\mathbf{w})\\\\ \\vdots \\\\ f(\\mathbf{x}_n; \\mathbf{w})\\end{bmatrix}.\n",
        "$$\n",
        "The second of these is actually a vector-valued function. This term may appear intimidating, but the idea is straightforward. A vector valued function is simply a vector whose elements are themselves defined as *functions*, i.e. it is a vector of functions, rather than a vector of scalars. The idea is so straightforward, that we are going to ignore it for the moment, and barely use it in the derivation. But it will reappear later when we introduce *basis functions*. So we will, for the moment, ignore the dependence of $\\mathbf{f}$ on $\\mathbf{w}$ and $\\mathbf{X}$ and simply summarise it by a vector of numbers\n",
        "$$\n",
        "\\mathbf{f} = \\begin{bmatrix}f_1\\\\f_2\\\\ \\vdots \\\\ f_n\\end{bmatrix}.\n",
        "$$\n",
        "This allows us to write our objective in the folowing, linear algebraic form,\n",
        "$$\n",
        "E(\\mathbf{w}) = (\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f})\n",
        "$$\n",
        "from the rules of inner products.\n",
        "\n",
        "But what of our matrix $\\mathbf{X}$ of input data? At this point, we need to dust off [*matrix-vector multiplication*](http://en.wikipedia.org/wiki/Matrix_multiplication). Matrix multiplication is simply a convenient way of performing many inner products together, and it's exactly what we need to summarise the operation\n",
        "$$\n",
        "f_i = \\mathbf{x}_i^\\top\\mathbf{w}.\n",
        "$$\n",
        "This operation tells us that each element of the vector $\\mathbf{f}$ (our vector valued function) is given by an inner product between $\\mathbf{x}_i$ and $\\mathbf{w}$. In other words it is a series of inner products. Let's look at the definition of matrix multiplication, it takes the form\n",
        "$$\n",
        "\\mathbf{c} = \\mathbf{B}\\mathbf{a}\n",
        "$$\n",
        "where $\\mathbf{c}$ might be a $k$ dimensional vector (which we can intepret as a $k\\times 1$ dimensional matrix), and $\\mathbf{B}$ is a $k\\times k$ dimensional matrix and $\\mathbf{a}$ is a $k$ dimensional vector ($k\\times 1$ dimensional matrix). \n",
        "\n",
        "The result of this multiplication is of the form\n",
        "$$\n",
        "\\begin{bmatrix}c_1\\\\c_2 \\\\ \\vdots \\\\ a_k\\end{bmatrix} = \n",
        "\\begin{bmatrix} b_{1,1} & b_{1, 2} & \\dots & b_{1, k} \\\\\n",
        "b_{2, 1} & b_{2, 2} & \\dots & b_{2, k} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "b_{k, 1} & b_{k, 2} & \\dots & b_{k, k} \\end{bmatrix} \\begin{bmatrix}a_1\\\\a_2 \\\\ \\vdots\\\\ c_k\\end{bmatrix} = \\begin{bmatrix} b_{1, 1}a_1 + b_{1, 2}a_2 + \\dots + b_{1, k}a_k\\\\\n",
        "b_{2, 1}a_1 + b_{2, 2}a_2 + \\dots + b_{2, k}a_k \\\\ \n",
        "\\vdots\\\\ \n",
        "b_{k, 1}a_1 + b_{k, 2}a_2 + \\dots + b_{k, k}a_k\\end{bmatrix}\n",
        "$$\n",
        "so we see that each element of the result, $\\mathbf{a}$ is simply the inner product between each *row* of $\\mathbf{B}$ and the vector $\\mathbf{c}$. Because we have defined each element of $\\mathbf{f}$ to be given by the inner product between each *row* of the design matrix and the vector $\\mathbf{w}$ we now can write the full operation in one matrix multiplication,\n",
        "$$\n",
        "\\mathbf{f} = \\mathbf{X}\\mathbf{w}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erj3V1UMEQEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = np.dot(X, w) # np.dot does matrix multiplication in python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZbpQyy3EQEn",
        "colab_type": "text"
      },
      "source": [
        "Combining this result with our objective function,\n",
        "$$\n",
        "E(\\mathbf{w}) = (\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f})\n",
        "$$\n",
        "we find we have defined the *model* with two equations. One equation tells us the form of our predictive function and how it depends on its parameters, the other tells us the form of our objective function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmtRQ0P5EQEo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aca0084b-2941-4495-e308-5ed3838341ae"
      },
      "source": [
        "resid = (y-f)\n",
        "E = np.dot(resid.T, resid) # matrix multiplication on a single vector is equivalent to a dot product.\n",
        "print(\"Error function is:\", E)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error function is: [[9.42454526e+10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl_bvnjcEQEp",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "The prediction for our movie recommender system had the form\n",
        "$$\n",
        "f_{i,j} = \\mathbf{u}_i^\\top \\mathbf{v}_j\n",
        "$$\n",
        "and the objective function was then\n",
        "$$\n",
        "E = \\sum_{i,j} s_{i,j}(y_{i,j} - f_{i, j})^2\n",
        "$$\n",
        "Try writing this down in matrix and vector form. How many of the terms can you do? For each variable and parameter carefully think about whether it should be represented as a matrix or vector. Do as many of the terms as you can. Use $\\LaTeX$ to give your answers and give the *dimensions* of any matrices you create."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wB5QekjEQEq",
        "colab_type": "text"
      },
      "source": [
        "#### Question 4 Answer\n",
        "\n",
        "As stated in the question, $f_{i,j} = \\mathbf{u}_i^\\top \\mathbf{v}_j $, where $\\mathbf{u_i}$ is a vector of $n$ users, and $\\mathbf{v_j}$ is a vector of $m$ films. Therefore, we can remove the sum by converting this into a matrix expression which will include all the information in one place; $\\mathbf{f = UV}$ where $\\mathbf{f}$ is a $n \\times 1$ dimensional matrix (or $n$ dimensional vector), as is \n",
        "\n",
        "**CONTINUE**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmTctieBEQEr",
        "colab_type": "text"
      },
      "source": [
        "## Objective Optimisation\n",
        "\n",
        "Our *model* has now been defined with two equations, the prediction function and the objective function. Next we will use multivariate calculus to define an *algorithm* to fit the model. The separation between model and algorithm is important and is often overlooked. Our model contains a function that shows how it will be used for prediction, and a function that describes the objective function we need to optimise to obtain a good set of parameters. \n",
        "\n",
        "The linear regression model we have described is still the same as the one we fitted above with a coordinate ascent algorithm. We have only played with the notation to obtain the same model in a matrix and vector notation. However, we will now fit this model with a different algorithm, one that is much faster. It is such a widely used algorithm that from the end user's perspective it doesn't even look like an algorithm, it just appears to be a single operation (or function). However, underneath the computer calls an algorithm to find the solution. Further, the algorithm we obtain is very widely used, and because of this it turns out to be highly optimised.\n",
        "\n",
        "Once again we are going to try and find the stationary points of our objective by finding the *stationary points*. However, the stationary points of a multivariate function, are a little bit more complext to find. Once again we need to find the point at which the derivative is zero, but now we need to use  *multivariate calculus* to find it. This involves learning a few additional rules of differentiation (that allow you to do the derivatives of a function with respect to  vector), but in the end it makes things quite a bit easier. We define vectorial derivatives as follows,\n",
        "$$\n",
        "\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}\\mathbf{w}} = \\begin{bmatrix}\\frac{\\partial E(\\mathbf{w})}{\\partial w_1}\\\\\\frac{\\partial E(\\mathbf{w})}{\\partial w_2}\\end{bmatrix}.\n",
        "$$\n",
        "where $\\frac{\\partial E(\\mathbf{w})}{\\partial w_1}$ is the [partial derivative](http://en.wikipedia.org/wiki/Partial_derivative) of the error function with respect to $w_1$.\n",
        "\n",
        "Differentiation through multiplications and additions is relatively straightforward, and since linear algebra is just multiplication and addition, then its rules of diffentiation are quite straightforward too, but slightly more complex than regular derivatives. \n",
        "\n",
        "### Matrix Differentiation\n",
        "\n",
        "We will need two rules of differentiation. The first is diffentiation of an inner product. By remebering that the inner product is made up of multiplication and addition, we can hope that its derivative is quite straightforward, and so it proves to be. We can start by thinking about the definition of the inner product,\n",
        "$$\n",
        "\\mathbf{a}^\\top\\mathbf{z} = \\sum_{i} a_i z_i,\n",
        "$$\n",
        "which if we were to take the derivative with respect to $z_k$ would simply return the gradient of the one term in the sum for which the derivative was non zero, that of $a_k$, so we know that \n",
        "$$\n",
        "\\frac{\\text{d}}{\\text{d}z_k} \\mathbf{a}^\\top \\mathbf{z} = a_k\n",
        "$$\n",
        "and by our definition of multivariate derivatives we can simply stack all the partial derivatives of this form in a vector to obtain the result that\n",
        "$$\n",
        "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{a}^\\top \\mathbf{z} = \\mathbf{a}.\n",
        "$$\n",
        "The second rule that's required is differentiation of a 'matrix quadratic'. A scalar quadratic in $z$ with coefficient $c$ has the form $cz^2$. If $\\mathbf{z}$ is a $k\\times 1$ vector and $\\mathbf{C}$ is a $k \\times k$ *matrix* of coefficients then the matrix quadratic form is written as $\\mathbf{z}^\\top \\mathbf{C}\\mathbf{z}$, which is itself a *scalar* quantity, but it is a function of a *vector*. \n",
        "\n",
        "#### Matching Dimensions in Matrix Multiplications\n",
        "\n",
        "There's a trick for telling that it's a scalar result. When you are doing maths with matrices, it's always worth pausing to perform a quick sanity check on the dimensions. Matrix multplication only works when the dimensions match. To be precise, the 'inner' dimension of the matrix must match. What is the inner dimension. If we multiply two matrices $\\mathbf{A}$ and $\\mathbf{B}$, the first of which has $k$ rows and $\\ell$ columns and the second of which has $p$ rows and $q$ columns, then we can check whether the multiplication works by writing the dimensionalities next to each other,\n",
        "$$\n",
        "\\mathbf{A} \\mathbf{B} \\rightarrow (k \\times \\underbrace{\\ell)(p}_\\text{inner dimensions} \\times q) \\rightarrow (k\\times q).\n",
        "$$\n",
        "The inner dimensions are the two inside dimensions, $\\ell$ and $p$. The multiplication will only work if $\\ell=p$. The result of the multiplication will then be a $k\\times q$ matrix: this dimensionality comes from the 'outer dimensions'. Note that matrix multiplication is not [*commutative*](http://en.wikipedia.org/wiki/Commutative_property). And if you change the order of the multiplication, \n",
        "$$\n",
        "\\mathbf{B} \\mathbf{A} \\rightarrow (\\ell \\times \\underbrace{k)(q}_\\text{inner dimensions} \\times p) \\rightarrow (\\ell \\times p).\n",
        "$$\n",
        "firstly it may no longer even work, because now the condition is that $k=q$, and secondly the result could be of a different dimensionality. An exception is if the matrices are square matrices (e.g. same number of rows as columns) and they are both *symmetric*. A symmetric matrix is one for which $\\mathbf{A}=\\mathbf{A}^\\top$, or equivalently, $a_{i,j} = a_{j,i}$ for all $i$ and $j$.  \n",
        "\n",
        "You will need to get used to working with matrices and vectors applying and developing new machine learning techniques. You should have come across them before, but you may not have used them as extensively as we will now do in this course. You should get used to using this trick to check your work and ensure you know what the dimension of an output matrix should be. For our matrix quadratic form, it turns out that we can see it as a special type of inner product.\n",
        "$$\n",
        "\\mathbf{z}^\\top\\mathbf{C}\\mathbf{z} \\rightarrow (1\\times \\underbrace{k) (k}_\\text{inner dimensions}\\times k) (k\\times 1) \\rightarrow \\mathbf{b}^\\top\\mathbf{z}\n",
        "$$\n",
        "where $\\mathbf{b} = \\mathbf{C}\\mathbf{z}$ so therefore the result is a scalar,\n",
        "$$\n",
        "\\mathbf{b}^\\top\\mathbf{z} \\rightarrow (1\\times \\underbrace{k) (k}_\\text{inner dimensions}\\times 1) \\rightarrow (1\\times 1)\n",
        "$$\n",
        "where a $(1\\times 1)$ matrix is recognised as a scalar.\n",
        "\n",
        "This implies that we should be able to differentiate this form, and indeed the rule for its differentiation is slightly more complex than the inner product, but still quite simple,\n",
        "$$\n",
        "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{z}^\\top\\mathbf{C}\\mathbf{z}= \\mathbf{C}\\mathbf{z} + \\mathbf{C}^\\top \\mathbf{z}.\n",
        "$$\n",
        "Note that in the special case where $\\mathbf{C}$ is symmetric then we have $\\mathbf{C} = \\mathbf{C}^\\top$ and the derivative simplifies to \n",
        "$$\n",
        "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{z}^\\top\\mathbf{C}\\mathbf{z}= 2\\mathbf{C}\\mathbf{z}.\n",
        "$$\n",
        "### Differentiating the Objective\n",
        "\n",
        "First, we need to compute the full objective by substituting our prediction function into the objective function to obtain the objective in terms of $\\mathbf{w}$. Doing this we obtain\n",
        "$$\n",
        "E(\\mathbf{w})= (\\mathbf{y} - \\mathbf{X}\\mathbf{w})^\\top (\\mathbf{y} - \\mathbf{X}\\mathbf{w}).\n",
        "$$\n",
        "We now need to differentiate this *quadratic form* to find the minimum. We differentiate with respect to the *vector* $\\mathbf{w}$. But before we do that, we'll expand the brackets in the quadratic form to obtain a series of scalar terms. The rules for bracket expansion across the vectors are similar to those for the scalar system giving,\n",
        "$$\n",
        "(\\mathbf{a} - \\mathbf{b})^\\top (\\mathbf{c} - \\mathbf{d}) = \\mathbf{a}^\\top \\mathbf{c} - \\mathbf{a}^\\top \\mathbf{d} - \\mathbf{b}^\\top \\mathbf{c} + \\mathbf{b}^\\top \\mathbf{d}\n",
        "$$\n",
        "which substituting for $\\mathbf{a} = \\mathbf{c} = \\mathbf{y}$ and $\\mathbf{b}=\\mathbf{d} = \\mathbf{X}\\mathbf{w}$ gives\n",
        "$$\n",
        "E(\\mathbf{w})= \\mathbf{y}^\\top\\mathbf{y} - 2\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w} + \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w}\n",
        "$$\n",
        "where we used the fact that $\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w}= \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{y}$. Now we can use our rules of differentiation to compute the derivative of this form, which is,\n",
        "$$\n",
        "\\frac{\\text{d}}{\\text{d}\\mathbf{w}}E(\\mathbf{w})=- 2\\mathbf{X}^\\top \\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w},\n",
        "$$\n",
        "where we have exploited the fact that $\\mathbf{X}^\\top\\mathbf{X}$ is symmetric to obtain this result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcPol7DZEQEr",
        "colab_type": "text"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Use the equivalence between our vector and our matrix formulations of linear regression, alongside our definition of vector derivates, to match the gradients we've computed directly for $\\frac{\\text{d}E(c, m)}{\\text{d}c}$ and $\\frac{\\text{d}E(c, m)}{\\text{d}m}$ to those for $\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}\\mathbf{w}}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om_qbpOiEQEs",
        "colab_type": "text"
      },
      "source": [
        "#### Question 5 Answer\n",
        "\n",
        "Write your answer to the question in this box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSFR7UR4EQEs",
        "colab_type": "text"
      },
      "source": [
        "## Update Equation for Global Optimum\n",
        "\n",
        "Once again, we need to find the minimum of our objective function. Using our likelihood for multiple input regression we can now minimize for our parameter vector $\\mathbf{w}$. Firstly, just as in the single input case, we seek stationary points by finding parameter vectors that solve for when the gradients are zero,\n",
        "$$\n",
        "\\mathbf{0}=- 2\\mathbf{X}^\\top \\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w},\n",
        "$$\n",
        "where $\\mathbf{0}$ is a *vector* of zeros. Rearranging this equation we find the solution to be\n",
        "$$\n",
        "\\mathbf{w} = \\left[\\mathbf{X}^\\top \\mathbf{X}\\right]^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
        "$$ \n",
        "where $\\mathbf{A}^{-1}$ denotes [*matrix inverse*](http://en.wikipedia.org/wiki/Invertible_matrix).\n",
        "\n",
        "### Solving the Multivariate System\n",
        "\n",
        "The solution for $\\mathbf{w}$ is given in terms of a matrix inverse, but computation of a matrix inverse requires, in itself, an algorithm to resolve it. You'll know this if you had to invert, by hand, a $3\\times 3$ matrix in high school. From a numerical stability perspective, it is also best not to compute the matrix inverse directly, but rather to ask the computer to *solve* the  system of linear equations given by\n",
        "$$\\mathbf{X}^\\top\\mathbf{X} \\mathbf{w} = \\mathbf{X}^\\top\\mathbf{y}$$\n",
        "for $\\mathbf{w}$. This can be done in `numpy` using the command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXF6gX08EQEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.linalg.solve?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw3L1ffIEQEu",
        "colab_type": "text"
      },
      "source": [
        "so we can obtain the solution using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puzfkDV1EQEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
        "print(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T3YlpjCEQEx",
        "colab_type": "text"
      },
      "source": [
        "We can map it back to the liner regression and plot the fit as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTdVnJkKEQEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = w[1]; c=w[0]\n",
        "f_test = m*x_test + c\n",
        "print(m)\n",
        "print(c)\n",
        "plt.plot(x_test, f_test, 'b-')\n",
        "plt.plot(x, y, 'rx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlVI3dYxEQE2",
        "colab_type": "text"
      },
      "source": [
        "## Multivariate Linear Regression\n",
        "\n",
        "A major advantage of the new system is that we can build a linear regression on a multivariate system. The matrix calculus didn't specify what the length of the vector $\\mathbf{x}$ should be, or equivalently the size of the design matrix. \n",
        "\n",
        "### Movie Body Count Data\n",
        "\n",
        "Let's load back in the movie body count data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AIOXkYuEQE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pods.datasets.movie_body_count()\n",
        "movies = data['Y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wUjVairEQE4",
        "colab_type": "text"
      },
      "source": [
        "Let's remind ourselves of the features we've been provided with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO_bZe9MEQE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(', '.join(movies.columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgw9ksGFEQE7",
        "colab_type": "text"
      },
      "source": [
        "Now we will build a design matrix based on the numeric features: year, Body_Count, Length_Minutes in an effort to predict the rating. We build the design matrix as follows:\n",
        "\n",
        "## Relation to Single Input System\n",
        "\n",
        "Bias as an additional feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLdggDHPEQE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "select_features = ['Year', 'Body_Count', 'Length_Minutes']\n",
        "X = movies.loc[:, select_features]\n",
        "X['Eins'] = 1 # add a column for the offset\n",
        "y = movies[['IMDB_Rating']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8zhrWMaEQE9",
        "colab_type": "text"
      },
      "source": [
        "Now let's perform a linear regression. But this time, we will create a pandas data frame for the result so we can store it in a form that we can visualise easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXkf7GHREQE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "w = pd.DataFrame(data=np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y)),  # solve linear regression here\n",
        "                 index = X.columns,  # columns of X become rows of w\n",
        "                 columns=['regression_coefficient']) # the column of X is the value of regression coefficient\n",
        "w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka_TeXXhEQFA",
        "colab_type": "text"
      },
      "source": [
        "We can check the residuals to see how good our estimates are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HFaw8pqEQFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(y - np.dot(X, w)).hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G08vW9dEQFC",
        "colab_type": "text"
      },
      "source": [
        "Which shows our model *hasn't* yet done a great job of representation, because the spread of values is large. We can check what the rating is dominated by in terms of regression coefficients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyagt-i-EQFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn8PRlB6EQFE",
        "colab_type": "text"
      },
      "source": [
        "Although we have to be a little careful about interpretation because our input values live on different scales, however it looks like we are dominated by the bias, with a small negative effect for later films (but bear in mind the years are large, so this effect is probably larger than it looks) and a positive effect for length. So it looks like long earlier films generally do better, but the residuals are so high that we probably haven't modelled the system very well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXFaD4QCEQFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('ui-uNlFHoms')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9sezmivEQFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('78YNphT90-k')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el4cSNCsEQFI",
        "colab_type": "text"
      },
      "source": [
        "## Solution with QR Decomposition\n",
        "\n",
        "Performing a solve instead of a matrix inverse is the more numerically stable approach, but we can do even better. A [QR-decomposition](http://en.wikipedia.org/wiki/QR_decomposition) of a matrix factorises it into a matrix which is an orthogonal matrix $\\mathbf{Q}$, so that $\\mathbf{Q}^\\top \\mathbf{Q} = \\mathbf{I}$. And a matrix which is upper triangular, $\\mathbf{R}$. \n",
        "$$\n",
        "\\mathbf{X}^\\top \\mathbf{X} \\boldsymbol{\\beta} = \\mathbf{X}^\\top \\mathbf{y}\n",
        "$$\n",
        "$$\n",
        "(\\mathbf{Q}\\mathbf{R})^\\top (\\mathbf{Q}\\mathbf{R})\\boldsymbol{\\beta} = (\\mathbf{Q}\\mathbf{R})^\\top \\mathbf{y}\n",
        "$$\n",
        "$$\n",
        "\\mathbf{R}^\\top (\\mathbf{Q}^\\top \\mathbf{Q}) \\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{R}^\\top \\mathbf{Q}^\\top \\mathbf{y}\n",
        "$$\n",
        "$$\n",
        "\\mathbf{R}^\\top \\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{R}^\\top \\mathbf{Q}^\\top \\mathbf{y}\n",
        "$$\n",
        "$$\n",
        "\\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{Q}^\\top \\mathbf{y}\n",
        "$$\n",
        "This is a more numerically stable solution because it removes the need to compute $\\mathbf{X}^\\top\\mathbf{X}$ as an intermediate. Computing $\\mathbf{X}^\\top\\mathbf{X}$ is a bad idea because it involves squaring all the elements of $\\mathbf{X}$ and thereby potentially reducing the numerical precision with which we can represent the solution. Operating on $\\mathbf{X}$ directly preserves the numerical precision of the model.\n",
        "\n",
        "This can be more particularly seen when we begin to work with *basis functions* in the next week. Some systems that can be resolved with the QR decomposition can not be resolved by using solve directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiXd5eCSEQFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy as sp\n",
        "Q, R = np.linalg.qr(X)\n",
        "w = sp.linalg.solve_triangular(R, np.dot(Q.T, y)) \n",
        "w = pd.DataFrame(w, index=X.columns)\n",
        "w"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}